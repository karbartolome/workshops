---
title: "Calibraci贸n de probabilidades"
subttile: "Estimaci贸n de mora mediante modelos de machine learning"
format: 
    revealjs:
        theme: [default, custom.scss]
        logo: logo-uba.jpeg
        footer: Facultad de Ciencias Econ贸micas - UBA
#format: beamer
jupyter: 
  kernelspec:
    name: "quarto-env"
    language: "python"
    display_name: "quarto-env"
execute:
  echo: false
  warning: false
  code-fold: false
  layout-align: center
---

```{python}
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from collections import Counter
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.compose import make_column_selector
from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier
from sklearn.calibration import calibration_curve, CalibratedClassifierCV
from sklearn.metrics import (
    classification_report,
    roc_auc_score,
    roc_curve,
    RocCurveDisplay,
    log_loss,
    recall_score,
    brier_score_loss,
    confusion_matrix,
    ConfusionMatrixDisplay,
)
from IPython.display import display
from custom_functions import (
    plot_distribution, plot_calibration_models, gain_table
)

import sklearn
sklearn.set_config(transform_output="pandas")
```

```{python}
#| echo: false
#| code-fold: false

color_verde = "#255255"
color_verde_claro = "#BDCBCC"

th_props = [
  ('font-size', '12px'),
  ('text-align', 'left'),
  ('font-weight', 'bold'),
  ('color', color_verde),
  ('background-color', color_verde_claro),
  ('border',f'1px solid {color_verde_claro}'),
  #('padding','12px 35px')
]

td_props = [
  ('font-size', '14px'),
  ('text-align', 'center'),
]

cell_hover_props = [  # for row hover use <tr> instead of <td>
    ('background-color', color_verde_claro)
]

headers_props = [
    ('text-align','center'),
    ('font-size','1.1em')
]
#dict(selector='th:not(.index_name)',props=headers_props)

styles = [
    dict(selector="th", props=th_props),
    dict(selector="td", props=td_props),
    dict(selector="td:hover",props=cell_hover_props),
    # dict(selector='th.col_heading',props=headers_props),
    dict(selector='th.col_heading.level0',props=headers_props),
    dict(selector='th.col_heading.level1',props=td_props)
]
```

# Introducci贸n a machine learning

::: {style="font-size: 50%;"}
## 驴Qu茅 es un modelo de clasificaci贸n?

Se busca predecir la [probabilidad de ocurrencia]{style="color: blue"} de un evento a partir de ciertas caracter铆sticas observables:

> $P(y=1) = f(X)$
>
> *Siendo y una variable que puede tomar 2 valores: 0 o 1*

<br> **Ejemplos de clasificaci贸n:**

-   [Titanic]{style="color: blue"}: Probabilidad de supervivencia
-   [Iris]{style="color: blue"}: Clasificaci贸n de especies de plantas
-   [German Credit]{style="color: blue"}: Probabilidad de default
:::

## Ejemplo: caso Titanic

::: {style="font-size: 50%;"}

Se consideran datos de [OpenML: Titanic](https://www.openml.org/search?type=data&status=active&id=43906) para ajustar un modelo que clasifique a individuos en sobrevivientes o no sobrevivientes del Titanic.

::: columns
::: {.column width="50%"}
```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
#| tbl-cap: "Datos de Titanic (muestra de 8 observaciones)"
#| label: tbl-titanic
data = datasets.fetch_openml(name="titanic", version=1)
y = data.target.astype("int")
X = (data.data[["age", "sex"]]
    # Construcci贸n de dummy de sex=mujer
    .assign(d_mujer=lambda df: [1 if i == "female" else 0 for i in df["sex"]])
    .drop("sex", axis=1)
)

(pd.concat([y, X], axis=1)
    .head(10)
    .style.format(precision=2).hide(axis=0)
    .set_table_styles(styles)
)
```
:::

::: {.column width="50%"}
```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
#| layout-align: center
#| fig-cap: "Modelo de 谩rbol de decisi贸n"
#| label: fig-decision-tree
clf = DecisionTreeClassifier(max_depth=1).fit(X, y)
plt.figure(figsize=(4.5, 4.5))
plot_tree(
    clf,
    filled=True,
    impurity=False,
    feature_names=X.columns.tolist(),
    class_names=["Sobrevivi贸", "No sobrevivi贸"],
);
```
:::
:::

A partir de los datos de la @tbl-titanic, el modelo de la @fig-decision-tree (profundidad=1) utiliza la variable de g茅nero para clasificar a los tripulantes del Titanic seg煤n supervivencia. Seg煤n el modelo, las mujeres sobreviven y los hombres no.
:::


## Ejemplo (Cont.)

::: {style="font-size: 50%;"}

```{python}
#| echo: true
#| code-fold: true
#| code-summary: "Ver c贸digo"
#| layout-align: center
#| layout-ncol: 2
y_pred = clf.predict(X)
ConfusionMatrixDisplay(
    confusion_matrix=confusion_matrix(y_true=y, y_pred=y_pred),
    display_labels=clf.classes_
).plot();

# Curva ROC
y_pred_proba = clf.predict_proba(X)[:, 1]
fpr, tpr, _ = roc_curve(y, y_pred_proba)
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()
```

:::

# Caso: German Credit

## Datos

::: {style="font-size: 50%;"}

```{python}
PATH_DATA = 'https://raw.githubusercontent.com/ayseceyda/german-credit-gini-analysis/master/gc.csv'
CLASE = "Risk"
```

```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
#| tbl-cap: "Datos de German Credit (muestra de 6 observaciones)"
#| label: tbl-credit-data
df = (pd.read_csv(PATH_DATA)
  .drop('Unnamed: 0', axis=1)
  .assign(Risk = lambda x: np.where(x['Risk']=='good',0,1))
)
print(f"Se cuenta con un dataset de {df.shape[0]} observaciones y {df.shape[1]} variables \n")

df.sample(6, random_state=42).style.format(precision=2).hide(axis=0).set_table_styles(styles)
```

:::

## Particiones
::: {style="font-size: 50%;"}

Partici贸n en dataset de entrenamiento, validaci贸n y evaluaci贸n.

- Dataset de entrenamiento --> Ajuste del modelo
- Dataset de validaci贸n --> Calibraci贸n del modelo
- Dataset de evaluaci贸n --> M茅tricas del modelo calibrado

```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
#| label: particiones
y = df[CLASE]
X = df.drop([CLASE], axis=1)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.5, shuffle=True, stratify=y, random_state=42
)

# Lo ideal es utilizar la partici贸n de validaci贸n para calibraci贸n
X_valid, X_test, y_valid, y_test = train_test_split(
    X_test, y_test, test_size=0.5, shuffle=True, stratify=y_test, random_state=42
)

print(f"N observaciones en entrenamiento: {X_train.shape[0]}")
print(f"N observaciones en validaci贸n: {X_valid.shape[0]}")
print(f"N observaciones en evaluaci贸n: {X_test.shape[0]}")
```

::: 

## Preprocesamiento

::: {style="font-size: 50%;"}

Se construye un pipeline de preprocesamiento de variables, diferenciando el procesamiento de variables categ贸ricas y num茅ricas

```{python}
#| echo: true
#| code-fold: true
#| code-summary: "Ver c贸digo"
numeric_transformer = Pipeline([
    ('impute', SimpleImputer(strategy='median')),
    ('scaler', MinMaxScaler())
])

categorical_transformer = Pipeline([
    ('ohe',OneHotEncoder(
        min_frequency=0.05,
        handle_unknown='infrequent_if_exist',
        sparse_output=False)
    )
])

preproc = ColumnTransformer([
    ('num', numeric_transformer,
      make_column_selector(dtype_include=['float','int'])),
    ('cat', categorical_transformer,
      make_column_selector(dtype_include=['object','category']))
], verbose_feature_names_out=False)
```

```{python}
#| echo: false
#| code-fold: false
#| classes: custom_class_html_display
preproc
```

::: 

## Modelado

```{python}
model = RandomForestClassifier(random_state=42)
model = LogisticRegression(random_state=42)
model = HistGradientBoostingClassifier(
    random_state=42,
    max_depth=4,
    learning_rate=0.1,
    class_weight={1:1,0:1}, # Sin pesos para las clases
    max_iter=1000
)

pipe = Pipeline([
    ('preproc', preproc),
    ('model', model)
])
pipe.fit(X_train, y_train)
```

## Evaluaci贸n


```{python}
print(classification_report(y_test, pipe.predict(X_test)))
```

# Calibraci贸n de probabilidades

::: {style="font-size: 50%;"}

## Calibraci贸n de probabilidades

Se realiza la calibraci贸n del modelo (preajustado) mediante 2 m茅todos: sigmoide e isot贸nico. Notar que la probabilidad promedio predicha mediante los modelos claibrados se corresponde con el % de clase positiva observado en el dataset de entrenamiento.

**M茅todos**

- Calibraci贸n sigmoide
- Calibraci贸n isot贸nica

**Referencias:**

- [Calibraci贸n de probabilidades en {scikit-learn}  ](https://scikit-learn.org/stable/modules/calibration.html)

:::

::: {style="font-size: 50%;"}


## Calibraci贸n sigmoide

Este m茅todo se basa en el modelo de regresi贸n log铆stica(Platt's):

> $P(y_{i}=1) = \frac{1}{1+(e^{伪+尾(pred_{i})})}$
>
> Siendo: $y_{i}$ la probabilidad calibrada para el individuo $i$ $pred_{i}$ el output del modelo no calibrado

En general este m茅todo es efectivo para muestras peque帽as o cuando el modelo no calibrado tiene errores de similares en predicciones de valores bajos y altos.

**Referencias:**

- Platt, John. (2000). Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods. Adv. Large Margin Classif, Volume 10.

:::

## Calibraci贸n sigmoide (Cont.)
::: {style="font-size: 50%;"}

```{python}
pipe_sigmoid = CalibratedClassifierCV(pipe, cv='prefit', method="sigmoid")
pipe_sigmoid.fit(X_valid, y_valid)

prob_pos_sigmoid = pipe_sigmoid.predict_proba(X_test)[:, 1]
preds = pd.DataFrame({
    'y_obs': y_test,
    'pred_class': pipe.predict(X_test),
    'pred_prob': pipe.predict_proba(X_test)[:,1],
    'pred_sigmoid': prob_pos_sigmoid,
    'pred_class_sigmoid': [1 if i>0.5 else 0 for i in prob_pos_sigmoid],
})

plt.figure(figsize=(10,5))
sns.regplot(
    x="pred_prob", y="y_obs", data=preds.sample(250, random_state=42),
    logistic=True, color='darkblue', scatter_kws={'alpha':0.3}
)

plt.axvline(x=preds.pred_prob.mean(), c='blue', label='Prob promedio modelo original')
plt.axvline(x=y_test.sum()/len(y_test), c='red', label='% clase 1 ~ prob promedio calibrada')
plt.axvline(x=prob_pos_sigmoid.mean(), c='green', label='Prob promedio calibrada')
plt.title('Probabilidad modelo original vs probabilidad con calibraci贸n')
plt.xlabel('Probabilidad predicha (sin calibraci贸n)')
plt.ylabel('Valor observado / Probabilidad calibrada')
plt.legend();
```

:::

::: {style="font-size: 50%;"}


## Calibraci贸n isot贸nica

```{python}
pipe_isotonic = CalibratedClassifierCV(pipe, cv='prefit', method="isotonic")
pipe_isotonic.fit(X_valid, y_valid)
```


```{python}
prob_pos_sigmoid = pipe_sigmoid.predict_proba(X_test)[:, 1]
prob_pos_isotonic = pipe_isotonic.predict_proba(X_test)[:, 1]

preds = pd.DataFrame({
    'y_obs': y_test,
    'pred_class': pipe.predict(X_test),
    'pred_prob': pipe.predict_proba(X_test)[:,1],
    'pred_sigmoid': prob_pos_sigmoid,
    'pred_class_sigmoid': [1 if i>0.5 else 0 for i in prob_pos_sigmoid],
    'pred_isotonic': prob_pos_isotonic,
    'pred_class_isotonic': [1 if i>0.5 else 0 for i in prob_pos_isotonic],
})

print(f'% observado: {y_test.sum()/len(y_test):.3}')
print(f'Prob promedio: {preds.pred_prob.mean():.3}')
print(f'Prob promedio (calibraci贸n sigmoide): {prob_pos_sigmoid.mean():.3}')
print(f'Prob promedio (calibraci贸n isot贸nica): {prob_pos_isotonic.mean():.3}')
```



:::

## Comparaci贸n de modelos
::: {style="font-size: 50%;"}


```{python}
# M茅tricas de ordenamiento
print(f"ROC AUC modelo={roc_auc_score(y_test, preds.pred_prob):.3f}")
print(f"ROC AUC modelo calibrado={roc_auc_score(y_test, preds.pred_sigmoid):.3f}")

# M茅tricas de probabilidad
print(f"Log loss modelo={log_loss(y_test, preds.pred_prob):.3f}")
print(f"Log loss modelo calibrado={log_loss(y_test, preds.pred_sigmoid):.3f}")
print(f"Brier modelo={brier_score_loss(y_test, preds.pred_prob):.3f}")
print(f"Brier modelo calibrado={brier_score_loss(y_test, preds.pred_sigmoid):.3f}")

# M茅tricas de clasificaci贸n (tomando como punto de corte prob=0.5)
print(f"Recall modelo={recall_score(y_test, preds.pred_class):.3f}")
print(f"Recall modelo calibrado={recall_score(y_test, preds.pred_class_sigmoid):.3f}")
```

Se visualizan las distribuciones de probabilidad predicha seg煤n el modelo calibrado y no calibrado.

```{python}
plot_distribution(
    data=preds, pred_column='pred_prob', subtitle='Modelo sin calibraci贸n'
)
plot_distribution(
    data=preds, pred_column='pred_sigmoid', subtitle='Modelo calibrado (sigmoide)'
)
```

:::

## Visualizaci贸n
::: {style="font-size: 50%;"}


```{python}
#| layout-ncol: 2
BINS = int(np.sqrt(preds.shape[0])/2)
plot_calibration_models(
        y_obs=preds['y_obs'],
        y_pred_prob=preds['pred_prob'],
        y_pred_prob_cal=preds['pred_sigmoid'],
        bins=BINS,
        strategy='uniform'
    )

plot_calibration_models(
        y_obs=preds['y_obs'],
        y_pred_prob=preds['pred_prob'],
        y_pred_prob_cal=preds['pred_isotonic'],
        bins=BINS,
        strategy='uniform'
    )
```

:::

## Tablas de ganancias
::: {style="font-size: 50%;"}

Se busca un modelo en donde la probabilidad promedio de cada bin se corresponda con el % de clase positiva observado en ese bin seg煤n las predicciones del modelo.

Esto es 煤til para la toma de decisiones, ya que permite establecer punto de cortes diferenciales en funci贸n de la aversi贸n en riesgo de la entidad.

Por ejemplo:

- En un modelo de scoring crediticio, otorgarle cr茅ditos a N individuos con probabilidad en cierto intervalo tiene un riesgo asociado (mora esperada)
- En un modelo de churn (abandono) de clientes, otorgarle una promoci贸n a individuos de cierto intervalo de probabilidad de abandono tiene un costo asociado (descuento para individuos que no abandonar铆an)
- Entre otros.

:::

## Tabla de ganancias (Cont.)
::: {style="font-size: 50%;"}


```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
#| tbl-cap: "Tabla de ganancias (modelo no calibrado)"
#| label: tbl-gain
gain_table(preds=preds, bins=5)
```

```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
#| tbl-cap: "Tabla de ganancias (calibraci贸n sigmoide)"
#| label: tbl-gain-sigmoid
gain_table(preds=preds, pred_column='pred_sigmoid', bins=5)
```

:::