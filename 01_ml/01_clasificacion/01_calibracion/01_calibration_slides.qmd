---
title: "Calibraci贸n de probabilidades"
subtitle: "Estimaci贸n de default mediante modelos de machine learning"
author: Karina A. Bartolom茅
institute: |
  Especialista en M茅todos Cuantitativos para la Gesti贸n y An谩lisis de Datos en Organizaciones (FCE, UBA). Lic. en Econom铆a, FCE, UNLP. L铆der t茅cnica de Ciencia de Datos en Ual谩

  <br>

  **Organizadora: Natalia R. Salaberry** <br>
  Doctoranda en la Universidad de Buenos Aires, Ciencias Econ贸micas. Magister en M茅todos Cuantitativos para la Gesti贸n y An谩lisis de Datos en Organizaciones (FCE, UBA). Lic. en Econom铆a, FCE, UBA. Investigadora en CIMBAGE (IADCOM), Docente de posgrados y Estad铆stica I, FCE, UBA
  <br> 

  **CIMBAGE (IADCOM)** - Facultad Ciencias Econ贸micas (UBA)

date: 2024-05-13
bibliography: bib.bib
nocite: |
  @*
format: 
    revealjs:
        theme: [default, custom.scss]
        logo: logo-uba.png
        footer: |
            <body>
            Cimbage - IADCOM | Facultad de Ciencias Econ贸micas - UBA   |  
            {{< fa brands github size=1x >}} [Repositorio](https://github.com/karbartolome/workshops)
            </body>
        self-contained: true
        embed-resources: true
        slide-number: true
        toc: true
        toc-depth: 1
        number-sections: true
        number-depth: 2
        title-slide-attributes:
            data-background-size: contain  
# format: beamer
jupyter: 
  kernelspec:
    name: "quarto-env"
    language: "python"
    display_name: "quarto-env"
execute:
  echo: false
  warning: false
  code-fold: false
  layout-align: center
lang: es
---


```{python}
#| echo: false
#| output: false
%load_ext autoreload
%autoreload 2
```


## Consideraciones previas
::: {style="font-size: 50%;"}

- Se realizar谩 una breve introducci贸n a modelos de aprendizaje autom谩tico, pero se recomienda tener alg煤n conocimiento previo para seguir el taller

- Durante el seminario se utilizar谩n los siguientes paquetes (**python**), con sus respectivas versiones.

```{python}
#| echo: true
#| code-fold: true
#| code-summary: "Librer铆as utilizadas"
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap, to_rgb
from great_tables import GT, from_column, style, loc
from collections import Counter

# from sklearn import datasets
# Modelado
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.compose import make_column_selector
from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.calibration import calibration_curve, CalibratedClassifierCV
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score,
    roc_curve,
    RocCurveDisplay,
    log_loss,
    recall_score,
    brier_score_loss,
    confusion_matrix,
    ConfusionMatrixDisplay,
)
from IPython.display import display, Markdown

# Funciones adicionales: 
from functions import (
    plot_distribution,
    plot_calibration_models,
    plot_calibration,
    calibrate_model,
    calibration_table,
    calculate_clf_metrics,
)

import sklearn
sklearn.set_config(transform_output="pandas")
```

```{python}
#| echo: false
import matplotlib
import great_tables
from IPython.display import display, Markdown, Latex
Markdown(f"""
**Procesamiento de datos**:\n
 pandas=={pd.__version__}\n
 numpy=={np.__version__}\n
\n
**Modelado**:\n
 scikit-learn=={sklearn.__version__}\n
\n
**Visualizaci贸n y tablas:**\n
 matplotlib=={matplotlib.__version__}\n
 seaborn=={sns.__version__}\n
 great_tables=={great_tables.__version__}\n
""")
```

```{python}
#| echo: false
#| code-fold: false
color_verde = "#255255"
color_verde_claro = "#BDCBCC"
```

:::


# Introducci贸n a machine learning

## Machine Learning
::: {style="font-size: 50%;"}
En general al hablar de **aprendizaje autom谩tico** se hace referencia a diversos tipos de modelos. En la @fig-ml-types se muestra una clasificaic贸n comunmente utilizada^[Para una introducci贸n a este tipo de modelos, ver @james2023introduction].

En esta presentaci贸n se analizar谩 el caso particular de los [modelos de clasificaci贸n]{style="color: blue"}, haciendo 茅nfasis en la [Estimaci贸n de probabilidad]{style="color: blue"}. 
```{mermaid}
%%| fig-cap: "Tipos de modelos de aprendizaje autom谩tico"
%%| label: fig-ml-types
%%{init: {'flowchart' : {'curve' : 'linear'}}}%%

flowchart LR
    ml[Machine Learning]:::greenclass1
    supervised[Aprendizaje <br> supervisado]:::greenclass1
    unsupervised[Aprendizaje <br> no supervisado]
    reinforce[Aprendizaje <br> por refuerzo]

    ml_clf[Modelos de <br>clasificaci贸n]:::greenclass1
    ml_reg[Modelos de <br>regresi贸n]
    ml_clfclass[Predicci贸n de<br>clase]
    ml_clfrank[Predicci贸n de<br>ordenamiento]
    ml_clfprob[Predicci贸n de <br>probabilidad]:::greenclass2

    ml---temp1[ ]

    temp1-->supervised
    temp1-->unsupervised
    temp1-->reinforce

    supervised---temp2[ ]

    temp2-->ml_clf
    temp2-->ml_reg

    ml_clf---temp3[ ]

    temp3-->ml_clfclass
    temp3-->ml_clfrank
    temp3-->ml_clfprob

    classDef greenclass2 fill:#255255,stroke:#333,stroke-width:2px,color:white;
    classDef greenclass1 fill:#BDCBCC,stroke:#333,stroke-width:2px,color:black;
    style temp1 fill:#FFFFFF00,stroke:#FFFFFF00,height:0px,width:0px;
    style temp2 fill:#FFFFFF00,stroke:#FFFFFF00,height:0px,width:0px;
    style temp3 fill:#FFFFFF00,stroke:#FFFFFF00,height:0px,width:0px;
```
:::

## 驴Qu茅 es un modelo de clasificaci贸n binaria?
::: {style="font-size: 50%;"}

Se busca [predecir la ocurrencia de un evento]{style="color: blue"} a partir de ciertas caracter铆sticas observables:

> $P(y=1) = f(X)$
>
> *y: variable que puede tomar 2 valores: 0 o 1*
>
> *X: matriz de nxm, siendo n la cantidad de observaciones y m la cantidad de variables (o atributos)*

::: {.fragment .fade-in}
<br> 
**Ejemplos populares de modelos de clasificaci贸n:**

锔**Iris**: Clasificaci贸n de especies de plantas

锔**Breast Cancer Wisconsin (Diagnostic)**: Clasificaci贸n de tumores benignos o malignos

锔**Titanic**: Clasificaci贸n de individuos en sobrevivientes y no sobrevivientes

::: {.fragment .highlight-red}
锔**German Credit**: Clasificaci贸n de individuos en riesgosos o no riesgosos
:::
:::
:::


# Caso: German Credit

## Datos

::: {style="font-size: 50%;"}

```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
PATH_DATA = 'https://raw.githubusercontent.com/karbartolome/workshops/main/01_ml/01_clasificacion/01_calibracion/df_german_credit.csv'
TARGET = "Risk"
# pd.read_csv(PATH_DATA).to_csv('df_german_credit.csv', index=False)
df = (pd.read_csv('df_german_credit.csv')
  .drop('Unnamed: 0', axis=1)
  .assign(Risk = lambda x: np.where(x['Risk']=='good',0,1))
)
```

Se cuenta con un dataset de `{python} df.shape[0]` observaciones y `{python} df.shape[1]` variables^[Fuente de los datos: [Statlog (German Credit Data)](https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data), en Kaggle en un formato m谩s simple: [German Credit Risk - With Target](https://www.kaggle.com/datasets/kabure/german-credit-data-with-risk)].

```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
#| tbl-cap: "Datos de German Credit (muestra de 6 observaciones)"
#| label: tbl-credit-data
def map_color(data):
    return (data[TARGET] == 1).map(
        {True: color_verde_claro, False: 'white'}
    )

(GT(df.sample(6, random_state=123)
        .set_index(TARGET)
        .reset_index()
    )
    .fmt_currency(columns="Credit amount")
    .tab_style(
        style=style.fill(color=map_color), locations=loc.body(columns=df.columns.tolist()),
    )
    .tab_style(
        style=style.text(color='red', weight = "bold"), locations=loc.body(TARGET),
    )
    .tab_options(
        column_labels_background_color=color_verde,
        table_font_names="Times New Roman"
    )
)
```

La variable objetivo (target) es Risk, donde el porcentaje de observaciones de clase 1 (riesgosos) es `{python} f"{df['Risk'].sum()/df.shape[0]:.1%}"`

:::

## Particiones
::: {style="font-size: 50%;"}

Partici贸n en dataset de entrenamiento, validaci贸n y evaluaci贸n.

- Dataset de entrenamiento --> Ajuste del modelo
- Dataset de validaci贸n --> Calibraci贸n del modelo
- Dataset de evaluaci贸n --> M茅tricas del modelo calibrado

```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
#| label: particiones
#| results: 'asis'
y = df[TARGET]
X = df.drop([TARGET], axis=1)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.5, shuffle=True, stratify=y, random_state=42
)

# Lo ideal es utilizar la partici贸n de validaci贸n para calibraci贸n
X_valid, X_test, y_valid, y_test = train_test_split(
    X_test, y_test, test_size=0.5, shuffle=True, stratify=y_test, random_state=42
)

display(Markdown(f"N observaciones en entrenamiento: {X_train.shape[0]}"))
display(Markdown(f"N observaciones en validaci贸n: {X_valid.shape[0]}"))
display(Markdown(f"N observaciones en evaluaci贸n: {X_test.shape[0]}"))
```
::: 


::: {style="font-size: 50%;"}
## Modelo de clasificaci贸n simple

Se consideran 2 variables para ajustar un modelo de arbol de decisi贸n con m谩xima profundidad=2

$$
P(\text{Risk}=1) = f(\text{Credit amount}, \text{Age})
$$

::: columns
::: {.column width="50%"}
::: {.fragment .fade-in}
```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
#| tbl-cap: "Datos de German Credit (2 variables)"
#| label: tbl-credit-data-1var
subset_cols = ['Age', 'Credit amount']

(GT(pd.concat([y_train, X_train], axis=1)
        .sample(6, random_state=123)
        .set_index(TARGET)
        [subset_cols]
        .reset_index()
    )
    .fmt_currency(columns="Credit amount")
    .tab_style(
        style=style.fill(color=map_color), locations=loc.body(columns=df.columns.tolist()),
    )
    .tab_style(
        style=style.text(color='red', weight = "bold"), locations=loc.body(TARGET),
    )
    .tab_options(
        column_labels_background_color=color_verde,
        table_font_names="Times New Roman"
    )
)
```

Ajuste del modelo:

```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
X_train_subset = X_train[subset_cols].copy()
clf = DecisionTreeClassifier(max_depth=2).fit(X_train_subset, y_train)
clf
```
:::
:::

::: {.column width="50%"}
::: {.fragment .fade-in}
```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
#| layout-align: center
#| fig-cap: "Modelo de 谩rbol de decisi贸n"
#| label: fig-credit-tree
colors = [color_verde, 'red']
labels = ['No riesgoso','Riesgoso']
plt.figure(figsize=(6,6))
arbol = plot_tree(
    clf,
    filled=True,
    impurity=False,
    feature_names=X_train_subset.columns.tolist(),
    class_names=labels,
    fontsize=8
)
for i, impurity, value in zip(arbol, clf.tree_.impurity, clf.tree_.value):
    # let the max value decide the color; whiten the color depending on impurity (gini)
    r, g, b = to_rgb(colors[np.argmax(value)])
    f = impurity * 2 # for N colors: f = impurity * N/(N-1) if N>1 else 0
    i.get_bbox_patch().set_facecolor((f + (1-f)*r, f + (1-f)*g, f + (1-f)*b))
    i.get_bbox_patch().set_edgecolor('black')
plt.show()
```
:::
:::
:::
:::

::: {style="font-size: 50%;"}
## Evaluaci贸n de un modelo de clasificaci贸n
Dados los datos de evaluaci贸n, se utiliza el modelo para predecir el valor de la variable objetivo. Mediante `predict()` se obtienen las predicciones de clase. Con `predict_proba()`el clasificador devuelve un score (valor entre 0 y 1). 

```{python}
#| echo: true
#| code-fold: true
#| code-summary: "Ver c贸digo"
preds = (pd.concat([y_test, X_test], axis=1)
    .set_index(TARGET)
    [subset_cols]
    .reset_index()
    .assign(
        Risk_pred = clf.predict(X_test[subset_cols]),
        Risk_pred_prob = clf.predict_proba(X_test[subset_cols])[:,1]
    )
)
```

::: {.columns}
::: {.column width="40%"}
::: {.fragment .fade-in}
```{python}
#| echo: true
#| code-fold: true
#| code-summary: "Ver c贸digo"
#| label: tbl-preds-tree
#| tbl-cap: 'Predicciones'
(GT(preds.sample(6, random_state=2).round(2))
    .fmt_currency(columns="Credit amount")
    .tab_style(
        style=style.fill(color=map_color), locations=loc.body(columns=df.columns.tolist()),
    )
    .tab_style(
        style=style.text(color='red', weight = "bold"), locations=loc.body(TARGET),
    )
    .tab_options(
        column_labels_background_color=color_verde,
        table_font_names="Times New Roman"
    )
)
```
:::
:::

::: {.column width="60%"}
::: {.fragment .fade-in}
```{python}
#| echo: true
#| code-fold: true
#| code-summary: "Ver c贸digo"
#| label: tbl-cm
#| tbl-cap: 'Matriz de confusi贸n'
display(GT(preds
    .groupby(['Risk','Risk_pred'], as_index=False).size()
    .pivot(index='Risk', columns='Risk_pred', values='size')
    .rename({0:'0',1:'1'}, axis=1)
    .reset_index()
    )
    .tab_spanner('Risk_pred', columns = ['0','1'])
    .data_color(
        columns=['0','1'],
        domain=[0,X.shape[0]],
        palette=[color_verde_claro, 'red'],
        na_color="white",
    )
)
```
:::
::: {.fragment .fade-in}
```{python}
#| echo: true
#| code-fold: true
#| code-summary: "Ver c贸digo"
#| label: fig-distrib-tree
#| fig-cap: 'Distribuci贸n de "probabilidad" predicha'
distrib=plot_distribution(
    data=preds,
    obs_column='Risk', 
    pred_column='Risk_pred_prob', 
    class_0_color=color_verde
)
distrib
```
:::
:::

:::

:::


## Evaluaci贸n de un modelo de clasificaci贸n (Cont.)
::: {style="font-size: 50%;"}
En la @fig-ml-metrics se presentan distintas m茅tricas de clasificaci贸n. En este caso el foco estar谩 sobre las m茅tricas basadas en probabilidad. 

```{mermaid}
%%| fig-cap: "M茅tricas de modelos de clasificaci贸n"
%%| label: fig-ml-metrics
%%{init: {'flowchart' : {'curve' : 'linear'}}}%%

flowchart LR
    ml[Modelo de <br>clasificaci贸n]
    metrics[M茅tricas]

    ml_clfclass[Predicci贸n de<br>clase]
    ml_clfrank[Predicci贸n de<br>ordenamiento]
    ml_clfprob[Predicci贸n de <br>probabilidad]:::greenclass2
    
    ml-->metrics
    metrics---temp1[ ]

    temp1-->ml_clfclass
    temp1-->ml_clfrank
    temp1-->ml_clfprob

    ml_clfclass---temp2[ ]
    temp2-->accuracy
    temp2-->precision
    temp2-->etc

    ml_clfrank---temp3[ ]
    temp3-->roc_auc
    
    ml_clfprob---temp4[ ]
    temp4-->log_loss:::greenclass2
    temp4-->brier_loss:::greenclass2

    classDef greenclass2 fill:#255255,stroke:#333,stroke-width:2px,color:white;
    classDef greenclass1 fill:#BDCBCC,stroke:#333,stroke-width:2px,color:black;
    style temp1 fill:#FFFFFF00,stroke:#FFFFFF00,height:0px,width:0px;
    style temp2 fill:#FFFFFF00,stroke:#FFFFFF00,height:0px,width:0px;
    style temp3 fill:#FFFFFF00,stroke:#FFFFFF00,height:0px,width:0px;
    style temp4 fill:#FFFFFF00,stroke:#FFFFFF00,height:0px,width:0px;
```
:::

## Evaluaci贸n de un modelo de clasificaci贸n (Cont.)
::: {style="font-size: 50%;"}

Siendo $N$ la cantidad de observaciones, $y_i$ el valor observado para la obseravci贸n $i$ y $\hat{y_i}$ el valor predicho para la observaci贸n $i$, se definen las funciones de p茅rdida:

::: {.nav-pills .panel-tabset}
## Log loss
Tambi茅n denominada Negative Mean Log-Likelihood

::: columns
::: {.column width="50%"}
$$
\text{Log Loss} = -\frac{1}{N} \sum_{i=1}^{N} \left( \color{red}{y_i \log(\hat{y_i})} + \color{blue}{(1 - y_i) \log(1 - \hat{y_i})} \right)
$$

> Si $y_i=1$ => $\text{Log Loss}_{i}=-\color{red}{\log(\hat{y_i})}$
>
> Si $y_i=0$ => $\text{Log Loss}_{i}=-\color{blue}{\log(1 - \hat{y_i})}$

- La p茅rdida es 0 si se tiene seguridad sobre una predicci贸n y la predicci贸n es correcta
- La p茅rdida es $\infty$ si se tiene seguridad sobre una predicci贸n y la predicci贸n es incorrecta

:::
::: {.column width="50%"}
```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
#| layout-align: center
#| fig-cap: "Logatitmo de una probabilidad"
#| label: fig-log
N=100
temp = (pd.DataFrame({
    'y_pred':[i/N for i in range(1,N,1)]
    })
    .assign(y_pred_log = lambda x: np.log(x['y_pred']))
).plot(x='y_pred', y='y_pred_log', figsize=(3,3), xlabel='Prob', ylabel='Log(Prob)');
```
:::
:::


## Brier loss
Error Cuadr谩tico Medio pero para clasificaci贸n:

$$
\text{Brier Loss} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y_i})^2
$$

:::
:::
# Comparaci贸n de modelos de ML
::: {style="font-size: 50%;"}
## Preprocesamiento

Muchos modelos de aprendizaje autom谩tico requieren que los datos sean num茅ricos. Para ello, se construye un pipeline de preprocesamiento de variables, diferenciando el procesamiento seg煤n tipo de variables: categ贸ricas y num茅ricas.

 [sklearn.preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html)

```{python}
#| echo: true
#| code-fold: true
#| code-summary: "Ver c贸digo"
numeric_transformer = Pipeline([
    ('impute', SimpleImputer(strategy='median')),
    ('scaler', MinMaxScaler())
])

categorical_transformer = Pipeline([
    ('ohe',OneHotEncoder(
        min_frequency=0.05,
        handle_unknown='infrequent_if_exist',
        sparse_output=False)
    )
])

preproc = ColumnTransformer([
    ('num', numeric_transformer,
      make_column_selector(dtype_include=['float','int'])),
    ('cat', categorical_transformer,
      make_column_selector(dtype_include=['object','category']))
], verbose_feature_names_out=False)
```
```{python}
#| echo: false
#| code-fold: false
#| classes: custom_class_html_display
#| layout-align: center
preproc
```

En la @tbl-credit-data-preproc se visualizan los datos luego del preprocesamiento. Esta es la matriz que ser谩 utilizada para ajustar m煤ltiples modelos de clasificaci贸n.
```{python}
#| echo: true
#| code-fold: true
#| code-summary: "C贸digo"
#| tbl-cap: "Datos de German Credit preprocesados (muestra de 2 observaciones)"
#| label: tbl-credit-data-preproc
display(GT(preproc.fit_transform(X_train).sample(2).round(2))
    .tab_options(
        column_labels_background_color=color_verde,
        table_font_names="Times New Roman"
    )
)
```

:::

## Modelado
::: {style="font-size: 50%;"}

Se ajustan distintos tipos de modelos reutilizando el mismo `pipeline` de preprocesamiento de datos:

```{python}
def gen_pipe(model):
    pipe = Pipeline([
        ('preproc', preproc),
        ('model',model)
    ])
    return pipe

pipe_hist = gen_pipe(
    model = HistGradientBoostingClassifier(
        max_depth=4,
        learning_rate=0.1,
        max_iter=1000,
        random_state=42,
    )
)
pipe_hist_balanced = gen_pipe(
    model = HistGradientBoostingClassifier(
        max_depth=4,
        learning_rate=0.1,
        max_iter=1000,
        random_state=42,
        class_weight='balanced'
    )
)

pipe_tree = gen_pipe(
    model = DecisionTreeClassifier(random_state=42)
)
pipe_tree = gen_pipe(
    model = DecisionTreeClassifier(random_state=42)
)
pipe_reglog = gen_pipe(
    model = LogisticRegression(random_state=42)
)
pipe_reglog_balanced = gen_pipe(
    model = LogisticRegression(random_state=42, class_weight='balanced')
)
pipe_svc = gen_pipe(model = SVC(random_state=42, probability=True))

models_dict = {
    'Hist gradient boosting': pipe_hist,
    'Decision tree': pipe_tree,
    'Logistc regression': pipe_reglog,
    'SVC': pipe_svc,
    'Logistc regression (balanced)': pipe_reglog_balanced,
    'Hist gradient boosting (balanced)': pipe_hist_balanced
}
```

::: {.nav-pills}
::: {.panel-tabset}
```{python}
# | output: asis
for i in models_dict.keys():
    display(Markdown(f"## {i}"))
    models_dict.get(i).fit(X_train, y_train)
    display(models_dict.get(i))
    display(Markdown(f" "))
```
:::
:::
:::

::: {style="font-size: 50%;"}
## Evaluaci贸n

Se calculan las m茅tricas de cada uno de los modelos:

```{python}
#| tbl-cap: "M茅tricas de los modelos en la partici贸n de evaluaci贸n"
#| label: tbl-metrics-uncalibrated
metrics_df = pd.DataFrame()
for i in models_dict.keys():
    pipe = models_dict.get(i)
    preds = pd.DataFrame({
        'y_true': y_test,
        'y_pred': pipe.predict(X_test),
        'y_pred_prob': pipe.predict_proba(X_test)[:,1],
    })
    m = calculate_clf_metrics(
        preds['y_true'], preds['y_pred'], preds['y_pred_prob'], 
        name=i
    ).reset_index().rename({'index':'Modelo'},axis=1)
    metrics_df = pd.concat([metrics_df, m], axis=0)

(GT(metrics_df.round(2))
    .data_color(
        columns=['Accuracy','Precision','Recall','F1','ROC AUC'],
        palette=[color_verde_claro, color_verde]
    )
    .data_color(
        columns=['Log Loss','Brier Loss'], palette=['white', 'red']
    )
)
```

:::

::: {style="font-size: 50%;"}
## Problema organizacional

Se utiliza el modelo para generar predicciones sobre las observaciones de test (@tbl-pred), agrupando las predicciones en 5 intervalos de probabilidad. La @tbl-pred-bins contiene la cantidad de observaciones por bin y el promedio de y_obs e y_pred. En la @fig-reliability se visualiza la probabilidad promedio por bin en el eje x y la fracci贸n de clase positiva observada en el eje y.

::: columns
::: {.column width="30%" .add-space}

```{python}
#| echo: true
#| code-fold: true
#| code-summary: "Ver c贸digo"
#| tbl-cap: "Predicciones"
#| label: tbl-pred
preds_df = (pd.DataFrame({
        'y_obs':y_test,
        'y_pred':pipe_hist.predict_proba(X_test)[:,1]
    })
    .assign(bin=lambda x: pd.qcut(x['y_pred'],q=5, precision=5))
)
preds_df['bin'] = pd.IntervalIndex(preds_df['bin']).map(lambda x: pd.Interval(round(x.left, 2), round(x.right, 2)))
(GT(preds_df
    .sample(3, random_state=123).round(4))
    .tab_options(
        column_labels_background_color=color_verde,
        table_font_names="Times New Roman"
    )
)
```

:::
::: {.column width="30%" .add-space}
```{python}
#| echo: true
#| code-fold: true
#| code-summary: "Ver c贸digo"
#| tbl-cap: "Bins de las predicciones"
#| label: tbl-pred-bins
(GT(preds_df.groupby('bin')
    .agg(
        N = ('y_obs','count'), 
        frac_positive=('y_obs','mean'),
        avg_pred = ('y_pred','mean')
    ).round(2).reset_index()
    )
    .tab_options(
        column_labels_background_color=color_verde,
        table_font_names="Times New Roman"
    )
)
```
:::
::: {.column width="30%"}

```{python}
# | echo: true
# | eval: true
# | code-fold: true
# | code-summary: "Ver c贸digo"
# | label: fig-reliability
# | fig-cap: "Gr谩fico de calibraci贸n (Reliability diagram)"
from sklearn.calibration import calibration_curve
prob_true, prob_pred = calibration_curve(
    y_test, pipe_hist.predict_proba(X_test)[:,1], 
    n_bins=5,
    strategy='uniform'
)
plt.figure(figsize=(3,3))
sns.lineplot(x=prob_pred, y=prob_true, color='red', label='Modelo')
sns.scatterplot(x=prob_pred, y=prob_true, color='red')
plt.axline([0, 0], [1, 1], c=color_verde)
plt.legend()
plt.xlabel("Probabilidad predicha")
plt.ylabel("Fracci贸n de positivos");
```
:::
:::
:::

# Calibraci贸n de probabilidades

::: {style="font-size: 50%;"}
## Calibraci贸n de probabilidades

**Objetivo:** 

Se busca encontrar una funci贸n que ajuste la relaci贸n entre los scores predichos por el modelo (predict_proba) y las probabilidades reales

> $P(y_i=1)= f(z)$
>
> Siendo: $P(y_{i}=1)$ la probabilidad calibrada para el individuo $i$ y $z_{i}$ el output del modelo no calibrado (score)

Un clasificador binario bien calibrado deber铆a clasificar de forma tal que para las observaciones que predice un score (predict_proba) = 0.8, se espera que un 80% de las observaciones correspondan a la clase positiva (1).

**Referencias:**

- [Calibraci贸n de probabilidades en {scikit-learn}  ](https://scikit-learn.org/stable/modules/calibration.html)

:::

::: {style="font-size: 50%;"}
## Calibraci贸n de probabilidades (Cont.)

::: {.fragment .fade-in}
**M茅todos de calibraci贸n**

::: {.fragment .highlight-red}
 Calibraci贸n Sigmoide (Platt scaling)

 Calibraci贸n Isot贸nica
:::

 Calibraci贸n Beta (Nuevo)

 Calibraci贸n Spline (Nuevo)
:::
:::

::: {style="font-size: 50%;"}
## Calibraci贸n sigmoide (Platt scaling)

Este m茅todo [@platt2000] asume una relaci贸n log铆stica entre los scores (z) y la probabilidad real (p):

> $log(\frac{p}{1-p})=\alpha+\beta(z_{i})$ 
>
>
> $P(y_{i}=1) = \frac{1}{1+(e^{-(伪+尾(z_{i}))})}$
>
>
> Siendo: $y_{i}$ el valor observado para el individuo $i$ y $z_{i}$ el output del modelo no calibrado

<br>
Se estiman 2 par谩metros ($\alpha$ y $\beta$), como en una regresi贸n log铆stica. 

- Requiere pocos datos

- Es 煤til cuando el modelo no calibrado tiene errores similares en predicci贸n de valores bajos y altos 

:::

::: {style="font-size: 50%;"}
## Calibraci贸n sigmoide (Platt scaling) (Cont.)

```{python}
# | echo: true
# | eval: false
# | code-fold: true
# | code-summary: "Ver c贸digo"
pipe_sigmoid_hist, _, preds_hist = calibrate_model(
    pipe=pipe_hist,
    X_valid=X_valid, y_valid=y_valid, 
    X_test=X_test, y_test=y_test,
    cal_sigmoid=True,
    cal_isotonic=False,
    model_name=''
)
plot_calibration(
    preds=preds_hist,
    y_pred_prob_calibrated='pred_sigmoid',
    model_name=''
)
```

::: {.nav-pills}
::: {.panel-tabset}

```{python}
# | output: asis
for i in models_dict.keys():
    display(Markdown(f"## {i}"))

    # Curvas de calibraci贸n
    pipe_sigmoid, _, preds = calibrate_model(
        pipe=models_dict.get(i), 
        X_valid=X_valid, y_valid=y_valid, 
        X_test=X_test, y_test=y_test,
        cal_sigmoid=True,
        cal_isotonic=False,
        model_name=i
    )
    plt.show()

    # Calibraci贸n 
    plot_calibration(
        preds=preds,
        y_pred_prob_calibrated='pred_sigmoid',
        model_name=i
    )
    plt.title('Calibraci贸n')
    plt.show()

    display(Markdown(f" "))
```
:::
:::

```{python}
# C谩lculo manual
# clf_log = LogisticRegression(random_state=42, C=0.1, solver="lbfgs")
# y_valid_pred_uncalibrated = pipe.predict_proba(X_valid)[:, 1]
# clf_log.fit(X=pd.DataFrame({"pred_prob": y_valid_pred_uncalibrated}), y=y_valid)

# preds["pred_sigmoid_manual"] = clf_log.predict_proba(preds[["pred_prob"]])[:, 1]

# Verificar por qu茅 no funciona
# plt.figure()
# sns.scatterplot(
#     x="pred_prob",
#     y="pred_sigmoid_manual",
#     data=preds,
#     alpha=0.7,
#     label="Calibraci贸n manual",
# )
```

:::

::: {style="font-size: 50%;"}
## Calibraci贸n isot贸nica

@Zadrozny2002 proponen un m茅todo alternativo al propuesto por @platt2000: calibrar probabilidades mediante el uso de un m茅todo de regresi贸n no param茅trico (**regresi贸n isot贸nica**). 

Si se asume que el modelo ordena bien, el mappeo de `scores` a probabilidades es `no decreciente`. De esta forma, este m茅todo genera una funci贸n escalonada no decreciente:

> $\sum_{i=1}^{n}(y_i - \hat{f_i})^2$
> 
> Sujeto a $\hat{f_i}$ >= $\hat{f_j}$ siempre $f_i$ > $f_j$ 
> $y_i$: etiqueta verdadera de la obseravci贸n $i$ y sea la salida del clasificador calibrado para la muestra (es decir, la probabilidad calibrada)

```{python}
# print(f'% observado: {y_test.sum()/len(y_test):.3}')
# print(f'Prob promedio: {preds.pred_prob.mean():.3}')
# print(f'Prob promedio (calibraci贸n sigmoide): {prob_pos_sigmoid.mean():.3}')
# print(f'Prob promedio (calibraci贸n isot贸nica): {prob_pos_isotonic.mean():.3}')
```

:::

::: {style="font-size: 50%;"}
## Calibraci贸n isot贸nica (Cont.)

::: {.nav-pills}
::: {.panel-tabset}

```{python}
# | output: asis
for i in models_dict.keys():
    display(Markdown(f"## {i}"))

    pipe_sigmoid, pipe_isotonic, preds = calibrate_model(
        pipe=models_dict.get(i), 
        X_valid=X_valid, y_valid=y_valid, 
        X_test=X_test, y_test=y_test,
        cal_sigmoid=True,
        cal_isotonic=True,
        model_name=i
    )
    plt.show()

    plot_calibration(preds=preds, y_pred_prob_calibrated='pred_isotonic', model_name=i)
    plt.show()

    display(Markdown(f" "))
```

:::
:::
:::


::: {style="font-size: 50%;"}
## Tabla de calibraci贸n
::: {.nav-pills}
::: {.panel-tabset}
```{python}
# | output: asis
for i in models_dict.keys():
    display(Markdown(f"## {i}"))
    _, _, preds = calibrate_model(
        pipe=models_dict.get(i), 
        X_valid=X_valid, y_valid=y_valid, 
        X_test=X_test, y_test=y_test,
        cal_sigmoid=True,
        cal_isotonic=True,
        model_name=i,
        plot_cal=False
    )
    display(Markdown('Modelo no calibrado'))
    calibration_table(preds=preds, bins=5, title='Modelo no calibrado')
    display(Markdown('Modelo calibrado (sigmoide)'))
    calibration_table(preds=preds, pred_column='pred_sigmoid', bins=5, title='Modelo calibrado (sigmoide)')
    display(Markdown(f" "))
```

:::
:::
:::


::: {style="font-size: 50%;"}
## Comparativa de m茅tricas

```{python}
metrics_df_sigmoid = pd.DataFrame()
metrics_df_isotonic = pd.DataFrame()
preds_dict = {}
for i in models_dict.keys():
    pipe = models_dict.get(i)
    _, _, preds = calibrate_model(
        pipe=models_dict.get(i), 
        X_valid=X_valid, y_valid=y_valid, 
        X_test=X_test, y_test=y_test,
        cal_sigmoid=True,
        cal_isotonic=True,
        model_name=i,
        plot_cal=False
    )
   
    m = calculate_clf_metrics(
        preds['y_obs'], preds['pred_class_sigmoid'], preds['pred_sigmoid'], 
        name=i
    ).reset_index().rename({'index':'Modelo'},axis=1)
    metrics_df_sigmoid = pd.concat([metrics_df_sigmoid, m], axis=0)

    m = calculate_clf_metrics(
        preds['y_obs'], preds['pred_class_sigmoid'], preds['pred_isotonic'], 
        name=i
    ).reset_index().rename({'index':'Modelo'},axis=1)
    metrics_df_isotonic = pd.concat([metrics_df_isotonic, m], axis=0)
```

::: {.nav-pills}
::: {.panel-tabset}

```{python}
# | output: asis
metrics_dfs = {
    'Modelo no calibrado': metrics_df,
    'Calibraci贸n sigmoide': metrics_df_sigmoid,
    'Calibraci贸n isot贸nica': metrics_df_isotonic
}
for i in metrics_dfs.keys():
    display(Markdown(f"## {i}"))
    display(GT(metrics_dfs.get(i).round(2))
        .data_color(
            columns=['Accuracy','Precision','Recall','F1','ROC AUC'],
            palette=[color_verde_claro, color_verde]
        )
        .data_color(
            columns=['Log Loss','Brier Loss'], palette=['white', 'red']
        )
    )
    display(Markdown(f" "))
```

:::
:::
:::


# Comentarios finales

::: {style="font-size: 50%;"}
## Comentarios finales

Se busca un modelo en donde la probabilidad promedio de cada bin se corresponda con el % de clase positiva observado en ese bin seg煤n las predicciones del modelo.

Esto es 煤til para la toma de decisiones, ya que permite establecer punto de cortes diferenciales en funci贸n de la probabilidad. 

:::

::: {style="font-size: 50%;"}
## Referencias / Recursos
::: {#refs}
:::
:::


## Contacto

{{< fa brands linkedin size=1x >}} [karinabartolome](https://www.linkedin.com/in/karinabartolome/)

{{< fa brands twitter size=1x >}} [karbartolome](https://twitter.com/karbartolome)

{{< fa brands github size=1x >}} [karbartolome](http://github.com/karbartolome)

{{< fa link >}} [Blog](https://karbartolome-blog.netlify.com)


