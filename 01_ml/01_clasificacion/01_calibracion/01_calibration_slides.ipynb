{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Calibración de probabilidades\n",
        "subtitle: Estimación de default mediante modelos de machine learning\n",
        "author: Karina Bartolomé\n",
        "institute: 'Lic. En economía (UNLP), Esp. Métodos Cuantitativos (UBA)<br><br>Organizadora: Natalia Salaberry <br> CIMBAGE (IADCOM) - Facultad Ciencias Económicas (UBA)'\n",
        "date: '2024-05-13'\n",
        "format:\n",
        "  revealjs:\n",
        "    theme:\n",
        "      - default\n",
        "      - custom_testing.scss\n",
        "    logo: logo-uba.jpeg\n",
        "    footer: |\n",
        "      <body>\n",
        "      Facultad de Ciencias Económicas - UBA  |\n",
        "      {{< fa brands github size=1x >}} [github.com/karbartolome/workshops](https://github.com/karbartolome/workshops)\n",
        "      </body>\n",
        "    self-contained: true\n",
        "    embed-resources: true\n",
        "    slide-number: true\n",
        "    toc: true\n",
        "    toc-depth: 1\n",
        "    number-sections: true\n",
        "    number-depth: 2\n",
        "    title-slide-attributes:\n",
        "      data-background-size: contain\n",
        "execute:\n",
        "  echo: false\n",
        "  warning: false\n",
        "  code-fold: false\n",
        "  layout-align: center\n",
        "lang: es\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {style=\"font-size: 50%;\"}\n",
        "## Consideraciones previas\n",
        "\n",
        "- Se realizará una breve introducción a modelos de aprendizaje automático, pero se recomienda tener algún conocimiento previo para seguir el taller. \n",
        "\n",
        "- Durante el seminario se utilizarán los siguientes paquetes (**python**):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Imports\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap, to_rgb\n",
        "from great_tables import GT, from_column, style, loc\n",
        "from collections import Counter\n",
        "\n",
        "# from sklearn import datasets\n",
        "# Modelado\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_selector\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    RocCurveDisplay,\n",
        "    log_loss,\n",
        "    recall_score,\n",
        "    brier_score_loss,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        ")\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Funciones adicionales: \n",
        "from custom_functions import (\n",
        "    plot_distribution,\n",
        "    plot_calibration_models,\n",
        "    plot_calibration,\n",
        "    calibrate_model,\n",
        "    calibration_table,\n",
        "    calculate_clf_metrics,\n",
        ")\n",
        "\n",
        "import sklearn\n",
        "sklearn.set_config(transform_output=\"pandas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "import matplotlib\n",
        "import great_tables\n",
        "from IPython.display import display, Markdown, Latex\n",
        "Markdown(f\"\"\"\n",
        "**Procesamiento de datos**:\\n\n",
        "📦 pandas=={pd.__version__}\\n\n",
        "📦 numpy=={np.__version__}\\n\n",
        "\\n\n",
        "**Modelado**:\\n\n",
        "📦 scikit-learn=={sklearn.__version__}\\n\n",
        "\\n\n",
        "**Visualización y tablas:**\\n\n",
        "📦 matplotlib=={matplotlib.__version__}\\n\n",
        "📦 seaborn=={sns.__version__}\\n\n",
        "📦 great_tables=={great_tables.__version__}\\n\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "#| code-fold: false\n",
        "color_verde = \"#255255\"\n",
        "color_verde_claro = \"#BDCBCC\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "# Introducción a machine learning\n",
        "\n",
        "## Machine Learning\n",
        "\n",
        "En general al hablar de machine learning se hace referencia a diversos tipos de modelos. En esta presentación se analizará el caso particular de los modelos de clasificación, haciendo énfasis en la estimación de probabilidad.\n",
        "\n",
        "```{mermaid}\n",
        "flowchart LR\n",
        "    ml[Machine Learning]\n",
        "    supervised[Aprendizaje <br> supervisado]\n",
        "    unsupervised[Aprendizaje <br> no supervisado]\n",
        "    semisupervised[Aprendizaje <br> semi supervizado]\n",
        "    reinforce[Aprendizaje <br> por refuerzo]\n",
        "\n",
        "    ml_clf[Modelos de <br>clasificación]\n",
        "    ml_reg[Modelos de <br>regresión]\n",
        "    ml_clfclass[Predicción de<br>clase]\n",
        "    ml_clfprob[Predicción de <br>probabilidad]:::redclass\n",
        "\n",
        "    ml-->supervised\n",
        "    ml-->unsupervised\n",
        "    ml-->semisupervised\n",
        "    ml-->reinforce\n",
        "\n",
        "    supervised-->ml_clf\n",
        "    supervised-->ml_reg\n",
        "    ml_clf-->ml_clfclass\n",
        "    ml_clf-->ml_clfprob\n",
        "\n",
        "    classDef redclass fill:#255255,stroke:#333,stroke-width:2px,color:white;\n",
        "    classDef blueclass fill:#BDCBCC,stroke:#333,stroke-width:2px,color:white;\n",
        "```\n",
        "\n",
        "\n",
        "## ¿Qué es un modelo de clasificación binaria?\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "\n",
        "Se busca predecir la [probabilidad de ocurrencia]{style=\"color: blue\"} de un evento a partir de ciertas características observables:\n",
        "\n",
        "> $P(y=1) = f(X)$\n",
        ">\n",
        "> *Siendo y una variable que puede tomar 2 valores: 0 o 1*\n",
        "\n",
        "::: {.fragment .fade-in}\n",
        "<br> \n",
        "**Ejemplos de clasificación:**\n",
        "\n",
        "▪️**Iris**: Clasificación de especies de plantas\n",
        "\n",
        "▪️**Titanic**: Clasificación de individuos en sobrevivientes y no sobrevivientes\n",
        "\n",
        "::: {.fragment .highlight-red}\n",
        "▪️**German Credit**: Clasificación de individuos en riesgosos o no riesgosos\n",
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "# Caso: German Credit\n",
        "\n",
        "## Datos\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Código\"\n",
        "PATH_DATA = 'https://raw.githubusercontent.com/ayseceyda/german-credit-gini-analysis/master/gc.csv'\n",
        "TARGET = \"Risk\"\n",
        "\n",
        "df = (pd.read_csv(PATH_DATA)\n",
        "  .drop('Unnamed: 0', axis=1)\n",
        "  .assign(Risk = lambda x: np.where(x['Risk']=='good',0,1))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se cuenta con un dataset de `{python} df.shape[0]` observaciones y `{python} df.shape[1]` variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Código\"\n",
        "#| tbl-cap: \"Datos de German Credit (muestra de 6 observaciones)\"\n",
        "#| label: tbl-credit-data\n",
        "def map_color(data):\n",
        "    return (data[TARGET] == 1).map(\n",
        "        {True: color_verde_claro, False: 'white'}\n",
        "    )\n",
        "\n",
        "(GT(df.sample(6, random_state=123)\n",
        "        .set_index(TARGET)\n",
        "        .reset_index()\n",
        "    )\n",
        "    .fmt_currency(columns=\"Credit amount\")\n",
        "    .tab_style(\n",
        "        style=style.fill(color=map_color), locations=loc.body(columns=df.columns.tolist()),\n",
        "    )\n",
        "    .tab_style(\n",
        "        style=style.text(color='red', weight = \"bold\"), locations=loc.body(TARGET),\n",
        "    )\n",
        "    .tab_options(\n",
        "        column_labels_background_color=color_verde,\n",
        "        table_font_names=\"Times New Roman\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La variable objetivo (target) es Risk, donde el porcentaje de observaciones de clase 1 (riesgosos) es `{python} f\"{df['Risk'].sum()/df.shape[0]:.1%}\"`\n",
        "\n",
        ":::\n",
        "\n",
        "## Particiones\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "\n",
        "Partición en dataset de entrenamiento, validación y evaluación.\n",
        "\n",
        "- Dataset de entrenamiento --> Ajuste del modelo\n",
        "- Dataset de validación --> Calibración del modelo\n",
        "- Dataset de evaluación --> Métricas del modelo calibrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Código\"\n",
        "#| label: particiones\n",
        "y = df[TARGET]\n",
        "X = df.drop([TARGET], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.5, shuffle=True, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Lo ideal es utilizar la partición de validación para calibración\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_test, y_test, test_size=0.5, shuffle=True, stratify=y_test, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"N observaciones en entrenamiento: {X_train.shape[0]}\")\n",
        "print(f\"N observaciones en validación: {X_valid.shape[0]}\")\n",
        "print(f\"N observaciones en evaluación: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: \n",
        "\n",
        "# Modelo simple\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Modelo de clasificación simple\n",
        "\n",
        "Se consideran 2 variables para ajustar un modelo de arbol de decisión con máxima profundidad=2\n",
        "\n",
        "$$\n",
        "P(\\text{Risk}=1) = f(\\text{Credit amount}, \\text{Age})\n",
        "$$\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"50%\"}\n",
        "::: {.fragment .fade-in}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Código\"\n",
        "#| tbl-cap: \"Datos de German Credit (2 variables)\"\n",
        "#| label: tbl-credit-data-1var\n",
        "subset_cols = ['Age', 'Credit amount']\n",
        "\n",
        "(GT(pd.concat([y_train, X_train], axis=1)\n",
        "        .sample(6, random_state=123)\n",
        "        .set_index(TARGET)\n",
        "        [subset_cols]\n",
        "        .reset_index()\n",
        "    )\n",
        "    .fmt_currency(columns=\"Credit amount\")\n",
        "    .tab_style(\n",
        "        style=style.fill(color=map_color), locations=loc.body(columns=df.columns.tolist()),\n",
        "    )\n",
        "    .tab_style(\n",
        "        style=style.text(color='red', weight = \"bold\"), locations=loc.body(TARGET),\n",
        "    )\n",
        "    .tab_options(\n",
        "        column_labels_background_color=color_verde,\n",
        "        table_font_names=\"Times New Roman\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ajuste del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Código\"\n",
        "X_train_subset = X_train[subset_cols].copy()\n",
        "clf = DecisionTreeClassifier(max_depth=2).fit(X_train_subset, y_train)\n",
        "clf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "::: {.fragment .fade-in}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Código\"\n",
        "#| layout-align: center\n",
        "#| fig-cap: \"Modelo de árbol de decisión\"\n",
        "#| label: fig-credit-tree\n",
        "colors = [color_verde, 'red']\n",
        "labels = ['No riesgoso','Riesgoso']\n",
        "plt.figure(figsize=(6,6))\n",
        "arbol = plot_tree(\n",
        "    clf,\n",
        "    filled=True,\n",
        "    impurity=False,\n",
        "    feature_names=X_train_subset.columns.tolist(),\n",
        "    class_names=labels,\n",
        "    fontsize=8\n",
        ")\n",
        "for i, impurity, value in zip(arbol, clf.tree_.impurity, clf.tree_.value):\n",
        "    # let the max value decide the color; whiten the color depending on impurity (gini)\n",
        "    r, g, b = to_rgb(colors[np.argmax(value)])\n",
        "    f = impurity * 2 # for N colors: f = impurity * N/(N-1) if N>1 else 0\n",
        "    i.get_bbox_patch().set_facecolor((f + (1-f)*r, f + (1-f)*g, f + (1-f)*b))\n",
        "    i.get_bbox_patch().set_edgecolor('black')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Evaluación de un modelo de clasificación\n",
        "::: columns\n",
        "::: {.column width=\"50%\"}\n",
        "::: {.fragment .fade-in}\n",
        "Se utiliza el método `clf.predict()`para predecir la clase (0,1) según el modelo (`clf`). A partir de la clase predicha se obtiene la matriz de confusión:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Ver código\"\n",
        "#| label: tbl-cm\n",
        "#| tbl-cap: 'Matriz de confusión'\n",
        "preds = pd.DataFrame({'Valor observado':y_test,'Valor predicho':clf.predict(X_test[subset_cols])})\n",
        "display(GT(preds\n",
        "    .groupby(['Valor observado','Valor predicho'], as_index=False).size()\n",
        "    .pivot(index='Valor observado', columns='Valor predicho', values='size')\n",
        "    .rename({0:'0',1:'1'}, axis=1)\n",
        "    .reset_index()\n",
        "    )\n",
        "    .tab_spanner('Valor predicho', columns = ['0','1'])\n",
        "    .data_color(\n",
        "        columns=['0','1'],\n",
        "        domain=[0,X.shape[0]],\n",
        "        palette=[color_verde_claro, 'red'],\n",
        "        na_color=\"white\",\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "::: {.fragment .fade-in}\n",
        "\n",
        "Además de predecir una clase, sklearn permite predecir una \"probabilidad\" con `clf.predict_proba()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Ver código\"\n",
        "#| label: tbl-predictproba\n",
        "#| tbl-cap: 'clf.predict_proba(), muestra de 2 observaciones'\n",
        "y_pred_proba = clf.predict_proba(X_test[subset_cols])[:, 1]\n",
        "preds = pd.DataFrame({\n",
        "    'y_obs':y_test,\n",
        "    'predict_proba':y_pred_proba\n",
        "})\n",
        "GT(preds.sample(2, random_state=42)).fmt_number('predict_proba')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrica_auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
        "metrica_logloss = log_loss(y_true=y_test, y_pred=y_pred_proba)\n",
        "metrica_brierloss = brier_score_loss(y_true=y_test, y_prob=y_pred_proba)\n",
        "\n",
        "print(f\"\"\"\n",
        "ROC AUC = {metrica_auc:.2}, Log loss = {metrica_logloss:.2}, Brier loss = {metrica_brierloss:.2}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Ver código\"\n",
        "#| label: fig-distrib-tree\n",
        "#| fig-cap: 'Distribución de \"probabilidad\" predicha'\n",
        "distrib=plot_distribution(data=preds, pred_column='predict_proba', class_0_color=color_verde)\n",
        "distrib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "# Modelos más complejos\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Preprocesamiento\n",
        "\n",
        "Se construye un pipeline de preprocesamiento de variables, diferenciando el procesamiento según tipo de datos: \n",
        "\n",
        "- Variables categóricas\n",
        "- Variables numéricas\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Ver código\"\n",
        "numeric_transformer = Pipeline([\n",
        "    ('impute', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline([\n",
        "    ('ohe',OneHotEncoder(\n",
        "        min_frequency=0.05,\n",
        "        handle_unknown='infrequent_if_exist',\n",
        "        sparse_output=False)\n",
        "    )\n",
        "])\n",
        "\n",
        "preproc = ColumnTransformer([\n",
        "    ('num', numeric_transformer,\n",
        "      make_column_selector(dtype_include=['float','int'])),\n",
        "    ('cat', categorical_transformer,\n",
        "      make_column_selector(dtype_include=['object','category']))\n",
        "], verbose_feature_names_out=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "#| code-fold: false\n",
        "#| classes: custom_class_html_display\n",
        "#| layout-align: center\n",
        "preproc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Código\"\n",
        "#| tbl-cap: \"Datos de German Credit preprocesados (muestra de 2 observaciones)\"\n",
        "#| label: tbl-credit-data-preproc\n",
        "display(GT(preproc.fit_transform(X_train).sample(2).round(2))\n",
        "    .tab_options(\n",
        "        column_labels_background_color=color_verde,\n",
        "        table_font_names=\"Times New Roman\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: \n",
        "\n",
        "\n",
        "## Modelado\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "\n",
        "Se ajustan distintos tipos de modelos reutilizando el mismo `pipeline` de preprocesamiento de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gen_pipe(model):\n",
        "    pipe = Pipeline([\n",
        "        ('preproc', preproc),\n",
        "        ('model',model)\n",
        "    ])\n",
        "    return pipe\n",
        "\n",
        "pipe_hist = gen_pipe(\n",
        "    model = HistGradientBoostingClassifier(\n",
        "        max_depth=4,\n",
        "        learning_rate=0.1,\n",
        "        max_iter=1000,\n",
        "        random_state=42,\n",
        "    )\n",
        ")\n",
        "pipe_hist_balanced = gen_pipe(\n",
        "    model = HistGradientBoostingClassifier(\n",
        "        max_depth=4,\n",
        "        learning_rate=0.1,\n",
        "        max_iter=1000,\n",
        "        random_state=42,\n",
        "        class_weight='balanced'\n",
        "    )\n",
        ")\n",
        "\n",
        "pipe_tree = gen_pipe(\n",
        "    model = DecisionTreeClassifier(random_state=42)\n",
        ")\n",
        "pipe_tree = gen_pipe(\n",
        "    model = DecisionTreeClassifier(random_state=42)\n",
        ")\n",
        "pipe_reglog = gen_pipe(\n",
        "    model = LogisticRegression(random_state=42)\n",
        ")\n",
        "pipe_reglog_balanced = gen_pipe(\n",
        "    model = LogisticRegression(random_state=42, class_weight='balanced')\n",
        ")\n",
        "pipe_svc = gen_pipe(model = SVC(random_state=42, probability=True))\n",
        "\n",
        "models_dict = {\n",
        "    'Hist gradient boosting': pipe_hist,\n",
        "    'Decision tree': pipe_tree,\n",
        "    'Logistc regression': pipe_reglog,\n",
        "    'SVC': pipe_svc,\n",
        "    'Logistc regression (balanced)': pipe_reglog_balanced,\n",
        "    'Hist gradient boosting (balanced)': pipe_hist_balanced\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.nav-pills}\n",
        "::: {.panel-tabset}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: asis\n",
        "for i in models_dict.keys():\n",
        "    display(Markdown(f\"## {i}\"))\n",
        "    models_dict.get(i).fit(X_train, y_train)\n",
        "    display(models_dict.get(i))\n",
        "    display(Markdown(f\" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Evaluación\n",
        "\n",
        "Se calculan las métricas de cada uno de los modelos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| tbl-cap: \"Métricas de los modelos en la partición de evaluación\"\n",
        "#| label: tbl-metrics-uncalibrated\n",
        "metrics_df = pd.DataFrame()\n",
        "for i in models_dict.keys():\n",
        "    pipe = models_dict.get(i)\n",
        "    preds = pd.DataFrame({\n",
        "        'y_true': y_test,\n",
        "        'y_pred': pipe.predict(X_test),\n",
        "        'y_pred_prob': pipe.predict_proba(X_test)[:,1],\n",
        "    })\n",
        "    m = calculate_clf_metrics(\n",
        "        preds['y_true'], preds['y_pred'], preds['y_pred_prob'], \n",
        "        name=i\n",
        "    ).reset_index().rename({'index':'Modelo'},axis=1)\n",
        "    metrics_df = pd.concat([metrics_df, m], axis=0)\n",
        "\n",
        "(GT(metrics_df.round(2))\n",
        "    .data_color(\n",
        "        columns=['Accuracy','Precision','Recall','F1','ROC AUC'],\n",
        "        palette=[color_verde_claro, color_verde]\n",
        "    )\n",
        "    .data_color(\n",
        "        columns=['Log Loss','Brier Loss'], palette=['white', 'red']\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Problema\n",
        "\n",
        "Planteo de problema organizacional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "# Calibración de probabilidades\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Calibración de probabilidades\n",
        "\n",
        "**Objetivo:** \n",
        "\n",
        "Se busca encontrar una función que ajuste la relación entre los scores predichos por el modelo (predict_proba) y las probabilidades reales\n",
        "\n",
        "> $P(y_i=1)= f(z)$\n",
        ">\n",
        "> Siendo: $P(y_{i}=1)$ la probabilidad calibrada para el individuo $i$ y $z_{i}$ el output del modelo no calibrado (score)\n",
        "\n",
        "Un clasificador binario bien calibrado debería clasificar de forma tal que para las observaciones que predice un score (predict_proba) = 0.8, se espera que un 80% de las observaciones correspondan a la clase positiva (1).\n",
        "\n",
        "**Referencias:**\n",
        "\n",
        "- [Calibración de probabilidades en {scikit-learn} 📦 ](https://scikit-learn.org/stable/modules/calibration.html)\n",
        "\n",
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Calibración de probabilidades (Cont.)\n",
        "\n",
        "::: {.fragment .fade-in}\n",
        "**Métodos de calibración**\n",
        "\n",
        "::: {.fragment .highlight-red}\n",
        " Calibración Sigmoide (Platt scaling)\n",
        "\n",
        " Calibración Isotónica\n",
        ":::\n",
        "\n",
        " Calibración Beta (Nuevo)\n",
        "\n",
        " Calibración Spline (Nuevo)\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Calibración sigmoide (Platt scaling)\n",
        "\n",
        "Este método asume una relación logística entre los scores (z) y la probabilidad real (p):\n",
        "\n",
        "> $log(\\frac{p}{1-p})=\\alpha+\\beta(z_{i})$ \n",
        ">\n",
        ">\n",
        "> $P(y_{i}=1) = \\frac{1}{1+(e^{-(α+β(z_{i}))})}$\n",
        ">\n",
        ">\n",
        "> Siendo: $y_{i}$ el valor observado para el individuo $i$ y $z_{i}$ el output del modelo no calibrado\n",
        "\n",
        "<br>\n",
        "Se estiman 2 parámetros ($\\alpha$ y $\\beta$), como en una regresión logística. \n",
        "\n",
        "- Requiere pocos datos\n",
        "\n",
        "- Es útil cuando el modelo no calibrado tiene errores similares en predicción de valores bajos y altos \n",
        "\n",
        "<br>\n",
        "**Referencias:**\n",
        "\n",
        "- Platt, John. (2000). Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods. Adv. Large Margin Classif, Volume 10 (pp. 61-74).\n",
        "\n",
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Calibración sigmoide (Platt scaling) (Cont.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | echo: true\n",
        "# | eval: false\n",
        "# | code-fold: true\n",
        "# | code-summary: \"Ver código\"\n",
        "pipe_sigmoid_hist, _, preds_hist = calibrate_model(\n",
        "    pipe=pipe_hist,\n",
        "    X_valid=X_valid, y_valid=y_valid, \n",
        "    X_test=X_test, y_test=y_test,\n",
        "    cal_sigmoid=True,\n",
        "    cal_isotonic=False,\n",
        "    model_name=''\n",
        ")\n",
        "plot_calibration(\n",
        "    preds=preds_hist,\n",
        "    y_pred_prob_calibrated='pred_sigmoid',\n",
        "    model_name=''\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.nav-pills}\n",
        "::: {.panel-tabset}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: asis\n",
        "for i in models_dict.keys():\n",
        "    display(Markdown(f\"## {i}\"))\n",
        "\n",
        "    # Curvas de calibración\n",
        "    pipe_sigmoid, _, preds = calibrate_model(\n",
        "        pipe=models_dict.get(i), \n",
        "        X_valid=X_valid, y_valid=y_valid, \n",
        "        X_test=X_test, y_test=y_test,\n",
        "        cal_sigmoid=True,\n",
        "        cal_isotonic=False,\n",
        "        model_name=i\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "    # Calibración \n",
        "    plot_calibration(\n",
        "        preds=preds,\n",
        "        y_pred_prob_calibrated='pred_sigmoid',\n",
        "        model_name=i\n",
        "    )\n",
        "    plt.title('Calibración')\n",
        "    plt.show()\n",
        "\n",
        "    display(Markdown(f\" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cálculo manual\n",
        "# clf_log = LogisticRegression(random_state=42, C=0.1, solver=\"lbfgs\")\n",
        "# y_valid_pred_uncalibrated = pipe.predict_proba(X_valid)[:, 1]\n",
        "# clf_log.fit(X=pd.DataFrame({\"pred_prob\": y_valid_pred_uncalibrated}), y=y_valid)\n",
        "\n",
        "# preds[\"pred_sigmoid_manual\"] = clf_log.predict_proba(preds[[\"pred_prob\"]])[:, 1]\n",
        "\n",
        "# Verificar por qué no funciona\n",
        "# plt.figure()\n",
        "# sns.scatterplot(\n",
        "#     x=\"pred_prob\",\n",
        "#     y=\"pred_sigmoid_manual\",\n",
        "#     data=preds,\n",
        "#     alpha=0.7,\n",
        "#     label=\"Calibración manual\",\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Calibración isotónica\n",
        "\n",
        "Se ajusta un regresor isotónico no paramétrico, que produce una función escalonada no decreciente:\n",
        "\n",
        "> $\\sum_{i=1}^{n}(y_i - \\hat{f_i})^2$\n",
        "> \n",
        "> Sujeto a $\\hat{f_i}$ >= $\\hat{f_j}$ siempre $f_i$ > $f_j$ \n",
        "> $y_i$: etiqueta verdadera de la obseravción $i$ y sea la salida del clasificador calibrado para la muestra (es decir, la probabilidad calibrada)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(f'% observado: {y_test.sum()/len(y_test):.3}')\n",
        "# print(f'Prob promedio: {preds.pred_prob.mean():.3}')\n",
        "# print(f'Prob promedio (calibración sigmoide): {prob_pos_sigmoid.mean():.3}')\n",
        "# print(f'Prob promedio (calibración isotónica): {prob_pos_isotonic.mean():.3}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Calibración isotónica (Cont.)\n",
        "\n",
        "::: {.nav-pills}\n",
        "::: {.panel-tabset}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: asis\n",
        "for i in models_dict.keys():\n",
        "    display(Markdown(f\"## {i}\"))\n",
        "\n",
        "    pipe_sigmoid, pipe_isotonic, preds = calibrate_model(\n",
        "        pipe=models_dict.get(i), \n",
        "        X_valid=X_valid, y_valid=y_valid, \n",
        "        X_test=X_test, y_test=y_test,\n",
        "        cal_sigmoid=True,\n",
        "        cal_isotonic=True,\n",
        "        model_name=i\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "    plot_calibration(preds=preds, y_pred_prob_calibrated='pred_isotonic', model_name=i)\n",
        "    plt.show()\n",
        "\n",
        "    display(Markdown(f\" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Tabla de calibración\n",
        "::: {.nav-pills}\n",
        "::: {.panel-tabset}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: asis\n",
        "for i in models_dict.keys():\n",
        "    display(Markdown(f\"## {i}\"))\n",
        "    _, _, preds = calibrate_model(\n",
        "        pipe=models_dict.get(i), \n",
        "        X_valid=X_valid, y_valid=y_valid, \n",
        "        X_test=X_test, y_test=y_test,\n",
        "        cal_sigmoid=True,\n",
        "        cal_isotonic=True,\n",
        "        model_name=i,\n",
        "        plot_cal=False\n",
        "    )\n",
        "    display(Markdown('Modelo no calibrado'))\n",
        "    calibration_table(preds=preds, bins=5, title='Modelo no calibrado')\n",
        "    display(Markdown('Modelo calibrado (sigmoide)'))\n",
        "    calibration_table(preds=preds, pred_column='pred_sigmoid', bins=5, title='Modelo calibrado (sigmoide)')\n",
        "    display(Markdown(f\" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Comparativa de métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_df_sigmoid = pd.DataFrame()\n",
        "metrics_df_isotonic = pd.DataFrame()\n",
        "preds_dict = {}\n",
        "for i in models_dict.keys():\n",
        "    pipe = models_dict.get(i)\n",
        "    _, _, preds = calibrate_model(\n",
        "        pipe=models_dict.get(i), \n",
        "        X_valid=X_valid, y_valid=y_valid, \n",
        "        X_test=X_test, y_test=y_test,\n",
        "        cal_sigmoid=True,\n",
        "        cal_isotonic=True,\n",
        "        model_name=i,\n",
        "        plot_cal=False\n",
        "    )\n",
        "   \n",
        "    m = calculate_clf_metrics(\n",
        "        preds['y_obs'], preds['pred_class_sigmoid'], preds['pred_sigmoid'], \n",
        "        name=i\n",
        "    ).reset_index().rename({'index':'Modelo'},axis=1)\n",
        "    metrics_df_sigmoid = pd.concat([metrics_df_sigmoid, m], axis=0)\n",
        "\n",
        "    m = calculate_clf_metrics(\n",
        "        preds['y_obs'], preds['pred_class_sigmoid'], preds['pred_isotonic'], \n",
        "        name=i\n",
        "    ).reset_index().rename({'index':'Modelo'},axis=1)\n",
        "    metrics_df_isotonic = pd.concat([metrics_df_isotonic, m], axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.nav-pills}\n",
        "::: {.panel-tabset}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: asis\n",
        "metrics_dfs = {\n",
        "    'Modelo no calibrado': metrics_df,\n",
        "    'Calibración sigmoide': metrics_df_sigmoid,\n",
        "    'Calibración isotónica': metrics_df_isotonic\n",
        "}\n",
        "for i in metrics_dfs.keys():\n",
        "    display(Markdown(f\"## {i}\"))\n",
        "    display(GT(metrics_dfs.get(i).round(2))\n",
        "        .data_color(\n",
        "            columns=['Accuracy','Precision','Recall','F1','ROC AUC'],\n",
        "            palette=[color_verde_claro, color_verde]\n",
        "        )\n",
        "        .data_color(\n",
        "            columns=['Log Loss','Brier Loss'], palette=['white', 'red']\n",
        "        )\n",
        "    )\n",
        "    display(Markdown(f\" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "# Comentarios finales\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Comentarios finales\n",
        "\n",
        "Se busca un modelo en donde la probabilidad promedio de cada bin se corresponda con el % de clase positiva observado en ese bin según las predicciones del modelo.\n",
        "\n",
        "Esto es útil para la toma de decisiones, ya que permite establecer punto de cortes diferenciales en función de la aversión en riesgo de la entidad.\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "- En un modelo de scoring crediticio, otorgarle créditos a N individuos con probabilidad en cierto intervalo tiene un riesgo asociado (mora esperada)\n",
        "- En un modelo de churn (abandono) de clientes, otorgarle una promoción a individuos de cierto intervalo de probabilidad de abandono tiene un costo asociado (descuento para individuos que no abandonarían)\n",
        "- Entre otros.\n",
        "\n",
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Referencias / Recursos\n",
        "\n",
        "[Probability Calibration Workshop - PyData 2020](https://www.youtube.com/watch?v=A1NGGV3Z4m4&list=PLeVfk5xTWHYBw22D52etymvcpxey4QFIk&ab_channel=numeristical)\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Contacto\n",
        "\n",
        "{{< fa brands linkedin size=1x >}} [karinabartolome](https://www.linkedin.com/in/karinabartolome/)\n",
        "\n",
        "{{< fa brands twitter size=1x >}} [@karbartolome](https://twitter.com/karbartolome)\n",
        "\n",
        "{{< fa brands github size=1x >}} [@karbartolome](http://github.com/karbartolome)\n",
        "\n",
        "{{< fa link >}} [Blog](https://karbartolome-blog.netlify.com)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "quarto-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
