{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Calibraci贸n de probabilidades\n",
        "subtitle: Estimaci贸n de default mediante modelos de machine learning\n",
        "author: Karina Bartolom茅\n",
        "institute: 'Lic. En econom铆a (UNLP), Esp. M茅todos Cuantitativos (UBA)<br><br>Organizadora: Natalia Salaberry <br> CIMBAGE (IADCOM) - Facultad Ciencias Econ贸micas (UBA)'\n",
        "date: '2024-05-13'\n",
        "format:\n",
        "  revealjs:\n",
        "    theme:\n",
        "      - default\n",
        "      - custom_testing.scss\n",
        "    logo: logo-uba.jpeg\n",
        "    footer: |\n",
        "      <body>\n",
        "      Facultad de Ciencias Econ贸micas - UBA  |\n",
        "      {{< fa brands github size=1x >}} [github.com/karbartolome/workshops](https://github.com/karbartolome/workshops)\n",
        "      </body>\n",
        "    self-contained: true\n",
        "    embed-resources: true\n",
        "    slide-number: true\n",
        "    toc: true\n",
        "    toc-depth: 1\n",
        "    number-sections: true\n",
        "    number-depth: 2\n",
        "    title-slide-attributes:\n",
        "      data-background-size: contain\n",
        "execute:\n",
        "  echo: false\n",
        "  warning: false\n",
        "  code-fold: false\n",
        "  layout-align: center\n",
        "lang: es\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {style=\"font-size: 50%;\"}\n",
        "## Consideraciones previas\n",
        "\n",
        "- Se realizar谩 una breve introducci贸n a modelos de aprendizaje autom谩tico, pero se recomienda tener alg煤n conocimiento previo para seguir el taller. \n",
        "\n",
        "- Durante el seminario se utilizar谩n los siguientes paquetes (**python**):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Imports\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap, to_rgb\n",
        "from great_tables import GT, from_column, style, loc\n",
        "from collections import Counter\n",
        "\n",
        "# from sklearn import datasets\n",
        "# Modelado\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_selector\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    RocCurveDisplay,\n",
        "    log_loss,\n",
        "    recall_score,\n",
        "    brier_score_loss,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        ")\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Funciones adicionales: \n",
        "from custom_functions import (\n",
        "    plot_distribution,\n",
        "    plot_calibration_models,\n",
        "    plot_calibration,\n",
        "    calibrate_model,\n",
        "    calibration_table,\n",
        "    calculate_clf_metrics,\n",
        ")\n",
        "\n",
        "import sklearn\n",
        "sklearn.set_config(transform_output=\"pandas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "import matplotlib\n",
        "import great_tables\n",
        "from IPython.display import display, Markdown, Latex\n",
        "Markdown(f\"\"\"\n",
        "**Procesamiento de datos**:\\n\n",
        " pandas=={pd.__version__}\\n\n",
        " numpy=={np.__version__}\\n\n",
        "\\n\n",
        "**Modelado**:\\n\n",
        " scikit-learn=={sklearn.__version__}\\n\n",
        "\\n\n",
        "**Visualizaci贸n y tablas:**\\n\n",
        " matplotlib=={matplotlib.__version__}\\n\n",
        " seaborn=={sns.__version__}\\n\n",
        " great_tables=={great_tables.__version__}\\n\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "#| code-fold: false\n",
        "color_verde = \"#255255\"\n",
        "color_verde_claro = \"#BDCBCC\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "# Introducci贸n a machine learning\n",
        "\n",
        "## Machine Learning\n",
        "\n",
        "En general al hablar de machine learning se hace referencia a diversos tipos de modelos. En esta presentaci贸n se analizar谩 el caso particular de los modelos de clasificaci贸n, haciendo 茅nfasis en la estimaci贸n de probabilidad.\n",
        "\n",
        "```{mermaid}\n",
        "flowchart LR\n",
        "    ml[Machine Learning]\n",
        "    supervised[Aprendizaje <br> supervisado]\n",
        "    unsupervised[Aprendizaje <br> no supervisado]\n",
        "    semisupervised[Aprendizaje <br> semi supervizado]\n",
        "    reinforce[Aprendizaje <br> por refuerzo]\n",
        "\n",
        "    ml_clf[Modelos de <br>clasificaci贸n]\n",
        "    ml_reg[Modelos de <br>regresi贸n]\n",
        "    ml_clfclass[Predicci贸n de<br>clase]\n",
        "    ml_clfprob[Predicci贸n de <br>probabilidad]:::redclass\n",
        "\n",
        "    ml-->supervised\n",
        "    ml-->unsupervised\n",
        "    ml-->semisupervised\n",
        "    ml-->reinforce\n",
        "\n",
        "    supervised-->ml_clf\n",
        "    supervised-->ml_reg\n",
        "    ml_clf-->ml_clfclass\n",
        "    ml_clf-->ml_clfprob\n",
        "\n",
        "    classDef redclass fill:#255255,stroke:#333,stroke-width:2px,color:white;\n",
        "    classDef blueclass fill:#BDCBCC,stroke:#333,stroke-width:2px,color:white;\n",
        "```\n",
        "\n",
        "\n",
        "## 驴Qu茅 es un modelo de clasificaci贸n binaria?\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "\n",
        "Se busca predecir la [probabilidad de ocurrencia]{style=\"color: blue\"} de un evento a partir de ciertas caracter铆sticas observables:\n",
        "\n",
        "> $P(y=1) = f(X)$\n",
        ">\n",
        "> *Siendo y una variable que puede tomar 2 valores: 0 o 1*\n",
        "\n",
        "::: {.fragment .fade-in}\n",
        "<br> \n",
        "**Ejemplos de clasificaci贸n:**\n",
        "\n",
        "锔**Iris**: Clasificaci贸n de especies de plantas\n",
        "\n",
        "锔**Titanic**: Clasificaci贸n de individuos en sobrevivientes y no sobrevivientes\n",
        "\n",
        "::: {.fragment .highlight-red}\n",
        "锔**German Credit**: Clasificaci贸n de individuos en riesgosos o no riesgosos\n",
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "# Caso: German Credit\n",
        "\n",
        "## Datos\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"C贸digo\"\n",
        "PATH_DATA = 'https://raw.githubusercontent.com/ayseceyda/german-credit-gini-analysis/master/gc.csv'\n",
        "TARGET = \"Risk\"\n",
        "\n",
        "df = (pd.read_csv(PATH_DATA)\n",
        "  .drop('Unnamed: 0', axis=1)\n",
        "  .assign(Risk = lambda x: np.where(x['Risk']=='good',0,1))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se cuenta con un dataset de `{python} df.shape[0]` observaciones y `{python} df.shape[1]` variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"C贸digo\"\n",
        "#| tbl-cap: \"Datos de German Credit (muestra de 6 observaciones)\"\n",
        "#| label: tbl-credit-data\n",
        "def map_color(data):\n",
        "    return (data[TARGET] == 1).map(\n",
        "        {True: color_verde_claro, False: 'white'}\n",
        "    )\n",
        "\n",
        "(GT(df.sample(6, random_state=123)\n",
        "        .set_index(TARGET)\n",
        "        .reset_index()\n",
        "    )\n",
        "    .fmt_currency(columns=\"Credit amount\")\n",
        "    .tab_style(\n",
        "        style=style.fill(color=map_color), locations=loc.body(columns=df.columns.tolist()),\n",
        "    )\n",
        "    .tab_style(\n",
        "        style=style.text(color='red', weight = \"bold\"), locations=loc.body(TARGET),\n",
        "    )\n",
        "    .tab_options(\n",
        "        column_labels_background_color=color_verde,\n",
        "        table_font_names=\"Times New Roman\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La variable objetivo (target) es Risk, donde el porcentaje de observaciones de clase 1 (riesgosos) es `{python} f\"{df['Risk'].sum()/df.shape[0]:.1%}\"`\n",
        "\n",
        ":::\n",
        "\n",
        "## Particiones\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "\n",
        "Partici贸n en dataset de entrenamiento, validaci贸n y evaluaci贸n.\n",
        "\n",
        "- Dataset de entrenamiento --> Ajuste del modelo\n",
        "- Dataset de validaci贸n --> Calibraci贸n del modelo\n",
        "- Dataset de evaluaci贸n --> M茅tricas del modelo calibrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"C贸digo\"\n",
        "#| label: particiones\n",
        "y = df[TARGET]\n",
        "X = df.drop([TARGET], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.5, shuffle=True, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Lo ideal es utilizar la partici贸n de validaci贸n para calibraci贸n\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_test, y_test, test_size=0.5, shuffle=True, stratify=y_test, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"N observaciones en entrenamiento: {X_train.shape[0]}\")\n",
        "print(f\"N observaciones en validaci贸n: {X_valid.shape[0]}\")\n",
        "print(f\"N observaciones en evaluaci贸n: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: \n",
        "\n",
        "# Modelo simple\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Modelo de clasificaci贸n simple\n",
        "\n",
        "Se consideran 2 variables para ajustar un modelo de arbol de decisi贸n con m谩xima profundidad=2\n",
        "\n",
        "$$\n",
        "P(\\text{Risk}=1) = f(\\text{Credit amount}, \\text{Age})\n",
        "$$\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"50%\"}\n",
        "::: {.fragment .fade-in}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"C贸digo\"\n",
        "#| tbl-cap: \"Datos de German Credit (2 variables)\"\n",
        "#| label: tbl-credit-data-1var\n",
        "subset_cols = ['Age', 'Credit amount']\n",
        "\n",
        "(GT(pd.concat([y_train, X_train], axis=1)\n",
        "        .sample(6, random_state=123)\n",
        "        .set_index(TARGET)\n",
        "        [subset_cols]\n",
        "        .reset_index()\n",
        "    )\n",
        "    .fmt_currency(columns=\"Credit amount\")\n",
        "    .tab_style(\n",
        "        style=style.fill(color=map_color), locations=loc.body(columns=df.columns.tolist()),\n",
        "    )\n",
        "    .tab_style(\n",
        "        style=style.text(color='red', weight = \"bold\"), locations=loc.body(TARGET),\n",
        "    )\n",
        "    .tab_options(\n",
        "        column_labels_background_color=color_verde,\n",
        "        table_font_names=\"Times New Roman\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ajuste del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"C贸digo\"\n",
        "X_train_subset = X_train[subset_cols].copy()\n",
        "clf = DecisionTreeClassifier(max_depth=2).fit(X_train_subset, y_train)\n",
        "clf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "::: {.fragment .fade-in}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"C贸digo\"\n",
        "#| layout-align: center\n",
        "#| fig-cap: \"Modelo de 谩rbol de decisi贸n\"\n",
        "#| label: fig-credit-tree\n",
        "colors = [color_verde, 'red']\n",
        "labels = ['No riesgoso','Riesgoso']\n",
        "plt.figure(figsize=(6,6))\n",
        "arbol = plot_tree(\n",
        "    clf,\n",
        "    filled=True,\n",
        "    impurity=False,\n",
        "    feature_names=X_train_subset.columns.tolist(),\n",
        "    class_names=labels,\n",
        "    fontsize=8\n",
        ")\n",
        "for i, impurity, value in zip(arbol, clf.tree_.impurity, clf.tree_.value):\n",
        "    # let the max value decide the color; whiten the color depending on impurity (gini)\n",
        "    r, g, b = to_rgb(colors[np.argmax(value)])\n",
        "    f = impurity * 2 # for N colors: f = impurity * N/(N-1) if N>1 else 0\n",
        "    i.get_bbox_patch().set_facecolor((f + (1-f)*r, f + (1-f)*g, f + (1-f)*b))\n",
        "    i.get_bbox_patch().set_edgecolor('black')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Evaluaci贸n de un modelo de clasificaci贸n\n",
        "::: columns\n",
        "::: {.column width=\"50%\"}\n",
        "::: {.fragment .fade-in}\n",
        "Se utiliza el m茅todo `clf.predict()`para predecir la clase (0,1) seg煤n el modelo (`clf`). A partir de la clase predicha se obtiene la matriz de confusi贸n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Ver c贸digo\"\n",
        "#| label: tbl-cm\n",
        "#| tbl-cap: 'Matriz de confusi贸n'\n",
        "preds = pd.DataFrame({'Valor observado':y_test,'Valor predicho':clf.predict(X_test[subset_cols])})\n",
        "display(GT(preds\n",
        "    .groupby(['Valor observado','Valor predicho'], as_index=False).size()\n",
        "    .pivot(index='Valor observado', columns='Valor predicho', values='size')\n",
        "    .rename({0:'0',1:'1'}, axis=1)\n",
        "    .reset_index()\n",
        "    )\n",
        "    .tab_spanner('Valor predicho', columns = ['0','1'])\n",
        "    .data_color(\n",
        "        columns=['0','1'],\n",
        "        domain=[0,X.shape[0]],\n",
        "        palette=[color_verde_claro, 'red'],\n",
        "        na_color=\"white\",\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "::: {.fragment .fade-in}\n",
        "\n",
        "Adem谩s de predecir una clase, sklearn permite predecir una \"probabilidad\" con `clf.predict_proba()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Ver c贸digo\"\n",
        "#| label: tbl-predictproba\n",
        "#| tbl-cap: 'clf.predict_proba(), muestra de 2 observaciones'\n",
        "y_pred_proba = clf.predict_proba(X_test[subset_cols])[:, 1]\n",
        "preds = pd.DataFrame({\n",
        "    'y_obs':y_test,\n",
        "    'predict_proba':y_pred_proba\n",
        "})\n",
        "GT(preds.sample(2, random_state=42)).fmt_number('predict_proba')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrica_auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
        "metrica_logloss = log_loss(y_true=y_test, y_pred=y_pred_proba)\n",
        "metrica_brierloss = brier_score_loss(y_true=y_test, y_prob=y_pred_proba)\n",
        "\n",
        "print(f\"\"\"\n",
        "ROC AUC = {metrica_auc:.2}, Log loss = {metrica_logloss:.2}, Brier loss = {metrica_brierloss:.2}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Ver c贸digo\"\n",
        "#| label: fig-distrib-tree\n",
        "#| fig-cap: 'Distribuci贸n de \"probabilidad\" predicha'\n",
        "distrib=plot_distribution(data=preds, pred_column='predict_proba', class_0_color=color_verde)\n",
        "distrib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "# Modelos m谩s complejos\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Preprocesamiento\n",
        "\n",
        "Se construye un pipeline de preprocesamiento de variables, diferenciando el procesamiento seg煤n tipo de datos: \n",
        "\n",
        "- Variables categ贸ricas\n",
        "- Variables num茅ricas\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Ver c贸digo\"\n",
        "numeric_transformer = Pipeline([\n",
        "    ('impute', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline([\n",
        "    ('ohe',OneHotEncoder(\n",
        "        min_frequency=0.05,\n",
        "        handle_unknown='infrequent_if_exist',\n",
        "        sparse_output=False)\n",
        "    )\n",
        "])\n",
        "\n",
        "preproc = ColumnTransformer([\n",
        "    ('num', numeric_transformer,\n",
        "      make_column_selector(dtype_include=['float','int'])),\n",
        "    ('cat', categorical_transformer,\n",
        "      make_column_selector(dtype_include=['object','category']))\n",
        "], verbose_feature_names_out=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "#| code-fold: false\n",
        "#| classes: custom_class_html_display\n",
        "#| layout-align: center\n",
        "preproc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"C贸digo\"\n",
        "#| tbl-cap: \"Datos de German Credit preprocesados (muestra de 2 observaciones)\"\n",
        "#| label: tbl-credit-data-preproc\n",
        "display(GT(preproc.fit_transform(X_train).sample(2).round(2))\n",
        "    .tab_options(\n",
        "        column_labels_background_color=color_verde,\n",
        "        table_font_names=\"Times New Roman\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: \n",
        "\n",
        "\n",
        "## Modelado\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "\n",
        "Se ajustan distintos tipos de modelos reutilizando el mismo `pipeline` de preprocesamiento de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gen_pipe(model):\n",
        "    pipe = Pipeline([\n",
        "        ('preproc', preproc),\n",
        "        ('model',model)\n",
        "    ])\n",
        "    return pipe\n",
        "\n",
        "pipe_hist = gen_pipe(\n",
        "    model = HistGradientBoostingClassifier(\n",
        "        max_depth=4,\n",
        "        learning_rate=0.1,\n",
        "        max_iter=1000,\n",
        "        random_state=42,\n",
        "    )\n",
        ")\n",
        "pipe_hist_balanced = gen_pipe(\n",
        "    model = HistGradientBoostingClassifier(\n",
        "        max_depth=4,\n",
        "        learning_rate=0.1,\n",
        "        max_iter=1000,\n",
        "        random_state=42,\n",
        "        class_weight='balanced'\n",
        "    )\n",
        ")\n",
        "\n",
        "pipe_tree = gen_pipe(\n",
        "    model = DecisionTreeClassifier(random_state=42)\n",
        ")\n",
        "pipe_tree = gen_pipe(\n",
        "    model = DecisionTreeClassifier(random_state=42)\n",
        ")\n",
        "pipe_reglog = gen_pipe(\n",
        "    model = LogisticRegression(random_state=42)\n",
        ")\n",
        "pipe_reglog_balanced = gen_pipe(\n",
        "    model = LogisticRegression(random_state=42, class_weight='balanced')\n",
        ")\n",
        "pipe_svc = gen_pipe(model = SVC(random_state=42, probability=True))\n",
        "\n",
        "models_dict = {\n",
        "    'Hist gradient boosting': pipe_hist,\n",
        "    'Decision tree': pipe_tree,\n",
        "    'Logistc regression': pipe_reglog,\n",
        "    'SVC': pipe_svc,\n",
        "    'Logistc regression (balanced)': pipe_reglog_balanced,\n",
        "    'Hist gradient boosting (balanced)': pipe_hist_balanced\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.nav-pills}\n",
        "::: {.panel-tabset}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: asis\n",
        "for i in models_dict.keys():\n",
        "    display(Markdown(f\"## {i}\"))\n",
        "    models_dict.get(i).fit(X_train, y_train)\n",
        "    display(models_dict.get(i))\n",
        "    display(Markdown(f\" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Evaluaci贸n\n",
        "\n",
        "Se calculan las m茅tricas de cada uno de los modelos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| tbl-cap: \"M茅tricas de los modelos en la partici贸n de evaluaci贸n\"\n",
        "#| label: tbl-metrics-uncalibrated\n",
        "metrics_df = pd.DataFrame()\n",
        "for i in models_dict.keys():\n",
        "    pipe = models_dict.get(i)\n",
        "    preds = pd.DataFrame({\n",
        "        'y_true': y_test,\n",
        "        'y_pred': pipe.predict(X_test),\n",
        "        'y_pred_prob': pipe.predict_proba(X_test)[:,1],\n",
        "    })\n",
        "    m = calculate_clf_metrics(\n",
        "        preds['y_true'], preds['y_pred'], preds['y_pred_prob'], \n",
        "        name=i\n",
        "    ).reset_index().rename({'index':'Modelo'},axis=1)\n",
        "    metrics_df = pd.concat([metrics_df, m], axis=0)\n",
        "\n",
        "(GT(metrics_df.round(2))\n",
        "    .data_color(\n",
        "        columns=['Accuracy','Precision','Recall','F1','ROC AUC'],\n",
        "        palette=[color_verde_claro, color_verde]\n",
        "    )\n",
        "    .data_color(\n",
        "        columns=['Log Loss','Brier Loss'], palette=['white', 'red']\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Problema\n",
        "\n",
        "Planteo de problema organizacional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "# Calibraci贸n de probabilidades\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Calibraci贸n de probabilidades\n",
        "\n",
        "**Objetivo:** \n",
        "\n",
        "Se busca encontrar una funci贸n que ajuste la relaci贸n entre los scores predichos por el modelo (predict_proba) y las probabilidades reales\n",
        "\n",
        "> $P(y_i=1)= f(z)$\n",
        ">\n",
        "> Siendo: $P(y_{i}=1)$ la probabilidad calibrada para el individuo $i$ y $z_{i}$ el output del modelo no calibrado (score)\n",
        "\n",
        "Un clasificador binario bien calibrado deber铆a clasificar de forma tal que para las observaciones que predice un score (predict_proba) = 0.8, se espera que un 80% de las observaciones correspondan a la clase positiva (1).\n",
        "\n",
        "**Referencias:**\n",
        "\n",
        "- [Calibraci贸n de probabilidades en {scikit-learn}  ](https://scikit-learn.org/stable/modules/calibration.html)\n",
        "\n",
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Calibraci贸n de probabilidades (Cont.)\n",
        "\n",
        "::: {.fragment .fade-in}\n",
        "**M茅todos de calibraci贸n**\n",
        "\n",
        "::: {.fragment .highlight-red}\n",
        " Calibraci贸n Sigmoide (Platt scaling)\n",
        "\n",
        " Calibraci贸n Isot贸nica\n",
        ":::\n",
        "\n",
        " Calibraci贸n Beta (Nuevo)\n",
        "\n",
        " Calibraci贸n Spline (Nuevo)\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Calibraci贸n sigmoide (Platt scaling)\n",
        "\n",
        "Este m茅todo asume una relaci贸n log铆stica entre los scores (z) y la probabilidad real (p):\n",
        "\n",
        "> $log(\\frac{p}{1-p})=\\alpha+\\beta(z_{i})$ \n",
        ">\n",
        ">\n",
        "> $P(y_{i}=1) = \\frac{1}{1+(e^{-(伪+尾(z_{i}))})}$\n",
        ">\n",
        ">\n",
        "> Siendo: $y_{i}$ el valor observado para el individuo $i$ y $z_{i}$ el output del modelo no calibrado\n",
        "\n",
        "<br>\n",
        "Se estiman 2 par谩metros ($\\alpha$ y $\\beta$), como en una regresi贸n log铆stica. \n",
        "\n",
        "- Requiere pocos datos\n",
        "\n",
        "- Es 煤til cuando el modelo no calibrado tiene errores similares en predicci贸n de valores bajos y altos \n",
        "\n",
        "<br>\n",
        "**Referencias:**\n",
        "\n",
        "- Platt, John. (2000). Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods. Adv. Large Margin Classif, Volume 10 (pp. 61-74).\n",
        "\n",
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Calibraci贸n sigmoide (Platt scaling) (Cont.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | echo: true\n",
        "# | eval: false\n",
        "# | code-fold: true\n",
        "# | code-summary: \"Ver c贸digo\"\n",
        "pipe_sigmoid_hist, _, preds_hist = calibrate_model(\n",
        "    pipe=pipe_hist,\n",
        "    X_valid=X_valid, y_valid=y_valid, \n",
        "    X_test=X_test, y_test=y_test,\n",
        "    cal_sigmoid=True,\n",
        "    cal_isotonic=False,\n",
        "    model_name=''\n",
        ")\n",
        "plot_calibration(\n",
        "    preds=preds_hist,\n",
        "    y_pred_prob_calibrated='pred_sigmoid',\n",
        "    model_name=''\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.nav-pills}\n",
        "::: {.panel-tabset}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: asis\n",
        "for i in models_dict.keys():\n",
        "    display(Markdown(f\"## {i}\"))\n",
        "\n",
        "    # Curvas de calibraci贸n\n",
        "    pipe_sigmoid, _, preds = calibrate_model(\n",
        "        pipe=models_dict.get(i), \n",
        "        X_valid=X_valid, y_valid=y_valid, \n",
        "        X_test=X_test, y_test=y_test,\n",
        "        cal_sigmoid=True,\n",
        "        cal_isotonic=False,\n",
        "        model_name=i\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "    # Calibraci贸n \n",
        "    plot_calibration(\n",
        "        preds=preds,\n",
        "        y_pred_prob_calibrated='pred_sigmoid',\n",
        "        model_name=i\n",
        "    )\n",
        "    plt.title('Calibraci贸n')\n",
        "    plt.show()\n",
        "\n",
        "    display(Markdown(f\" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C谩lculo manual\n",
        "# clf_log = LogisticRegression(random_state=42, C=0.1, solver=\"lbfgs\")\n",
        "# y_valid_pred_uncalibrated = pipe.predict_proba(X_valid)[:, 1]\n",
        "# clf_log.fit(X=pd.DataFrame({\"pred_prob\": y_valid_pred_uncalibrated}), y=y_valid)\n",
        "\n",
        "# preds[\"pred_sigmoid_manual\"] = clf_log.predict_proba(preds[[\"pred_prob\"]])[:, 1]\n",
        "\n",
        "# Verificar por qu茅 no funciona\n",
        "# plt.figure()\n",
        "# sns.scatterplot(\n",
        "#     x=\"pred_prob\",\n",
        "#     y=\"pred_sigmoid_manual\",\n",
        "#     data=preds,\n",
        "#     alpha=0.7,\n",
        "#     label=\"Calibraci贸n manual\",\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Calibraci贸n isot贸nica\n",
        "\n",
        "Se ajusta un regresor isot贸nico no param茅trico, que produce una funci贸n escalonada no decreciente:\n",
        "\n",
        "> $\\sum_{i=1}^{n}(y_i - \\hat{f_i})^2$\n",
        "> \n",
        "> Sujeto a $\\hat{f_i}$ >= $\\hat{f_j}$ siempre $f_i$ > $f_j$ \n",
        "> $y_i$: etiqueta verdadera de la obseravci贸n $i$ y sea la salida del clasificador calibrado para la muestra (es decir, la probabilidad calibrada)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(f'% observado: {y_test.sum()/len(y_test):.3}')\n",
        "# print(f'Prob promedio: {preds.pred_prob.mean():.3}')\n",
        "# print(f'Prob promedio (calibraci贸n sigmoide): {prob_pos_sigmoid.mean():.3}')\n",
        "# print(f'Prob promedio (calibraci贸n isot贸nica): {prob_pos_isotonic.mean():.3}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Calibraci贸n isot贸nica (Cont.)\n",
        "\n",
        "::: {.nav-pills}\n",
        "::: {.panel-tabset}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: asis\n",
        "for i in models_dict.keys():\n",
        "    display(Markdown(f\"## {i}\"))\n",
        "\n",
        "    pipe_sigmoid, pipe_isotonic, preds = calibrate_model(\n",
        "        pipe=models_dict.get(i), \n",
        "        X_valid=X_valid, y_valid=y_valid, \n",
        "        X_test=X_test, y_test=y_test,\n",
        "        cal_sigmoid=True,\n",
        "        cal_isotonic=True,\n",
        "        model_name=i\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "    plot_calibration(preds=preds, y_pred_prob_calibrated='pred_isotonic', model_name=i)\n",
        "    plt.show()\n",
        "\n",
        "    display(Markdown(f\" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Tabla de calibraci贸n\n",
        "::: {.nav-pills}\n",
        "::: {.panel-tabset}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: asis\n",
        "for i in models_dict.keys():\n",
        "    display(Markdown(f\"## {i}\"))\n",
        "    _, _, preds = calibrate_model(\n",
        "        pipe=models_dict.get(i), \n",
        "        X_valid=X_valid, y_valid=y_valid, \n",
        "        X_test=X_test, y_test=y_test,\n",
        "        cal_sigmoid=True,\n",
        "        cal_isotonic=True,\n",
        "        model_name=i,\n",
        "        plot_cal=False\n",
        "    )\n",
        "    display(Markdown('Modelo no calibrado'))\n",
        "    calibration_table(preds=preds, bins=5, title='Modelo no calibrado')\n",
        "    display(Markdown('Modelo calibrado (sigmoide)'))\n",
        "    calibration_table(preds=preds, pred_column='pred_sigmoid', bins=5, title='Modelo calibrado (sigmoide)')\n",
        "    display(Markdown(f\" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Comparativa de m茅tricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_df_sigmoid = pd.DataFrame()\n",
        "metrics_df_isotonic = pd.DataFrame()\n",
        "preds_dict = {}\n",
        "for i in models_dict.keys():\n",
        "    pipe = models_dict.get(i)\n",
        "    _, _, preds = calibrate_model(\n",
        "        pipe=models_dict.get(i), \n",
        "        X_valid=X_valid, y_valid=y_valid, \n",
        "        X_test=X_test, y_test=y_test,\n",
        "        cal_sigmoid=True,\n",
        "        cal_isotonic=True,\n",
        "        model_name=i,\n",
        "        plot_cal=False\n",
        "    )\n",
        "   \n",
        "    m = calculate_clf_metrics(\n",
        "        preds['y_obs'], preds['pred_class_sigmoid'], preds['pred_sigmoid'], \n",
        "        name=i\n",
        "    ).reset_index().rename({'index':'Modelo'},axis=1)\n",
        "    metrics_df_sigmoid = pd.concat([metrics_df_sigmoid, m], axis=0)\n",
        "\n",
        "    m = calculate_clf_metrics(\n",
        "        preds['y_obs'], preds['pred_class_sigmoid'], preds['pred_isotonic'], \n",
        "        name=i\n",
        "    ).reset_index().rename({'index':'Modelo'},axis=1)\n",
        "    metrics_df_isotonic = pd.concat([metrics_df_isotonic, m], axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.nav-pills}\n",
        "::: {.panel-tabset}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: asis\n",
        "metrics_dfs = {\n",
        "    'Modelo no calibrado': metrics_df,\n",
        "    'Calibraci贸n sigmoide': metrics_df_sigmoid,\n",
        "    'Calibraci贸n isot贸nica': metrics_df_isotonic\n",
        "}\n",
        "for i in metrics_dfs.keys():\n",
        "    display(Markdown(f\"## {i}\"))\n",
        "    display(GT(metrics_dfs.get(i).round(2))\n",
        "        .data_color(\n",
        "            columns=['Accuracy','Precision','Recall','F1','ROC AUC'],\n",
        "            palette=[color_verde_claro, color_verde]\n",
        "        )\n",
        "        .data_color(\n",
        "            columns=['Log Loss','Brier Loss'], palette=['white', 'red']\n",
        "        )\n",
        "    )\n",
        "    display(Markdown(f\" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "# Comentarios finales\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Comentarios finales\n",
        "\n",
        "Se busca un modelo en donde la probabilidad promedio de cada bin se corresponda con el % de clase positiva observado en ese bin seg煤n las predicciones del modelo.\n",
        "\n",
        "Esto es 煤til para la toma de decisiones, ya que permite establecer punto de cortes diferenciales en funci贸n de la aversi贸n en riesgo de la entidad.\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "- En un modelo de scoring crediticio, otorgarle cr茅ditos a N individuos con probabilidad en cierto intervalo tiene un riesgo asociado (mora esperada)\n",
        "- En un modelo de churn (abandono) de clientes, otorgarle una promoci贸n a individuos de cierto intervalo de probabilidad de abandono tiene un costo asociado (descuento para individuos que no abandonar铆an)\n",
        "- Entre otros.\n",
        "\n",
        ":::\n",
        "\n",
        "::: {style=\"font-size: 50%;\"}\n",
        "## Referencias / Recursos\n",
        "\n",
        "[Probability Calibration Workshop - PyData 2020](https://www.youtube.com/watch?v=A1NGGV3Z4m4&list=PLeVfk5xTWHYBw22D52etymvcpxey4QFIk&ab_channel=numeristical)\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Contacto\n",
        "\n",
        "{{< fa brands linkedin size=1x >}} [karinabartolome](https://www.linkedin.com/in/karinabartolome/)\n",
        "\n",
        "{{< fa brands twitter size=1x >}} [@karbartolome](https://twitter.com/karbartolome)\n",
        "\n",
        "{{< fa brands github size=1x >}} [@karbartolome](http://github.com/karbartolome)\n",
        "\n",
        "{{< fa link >}} [Blog](https://karbartolome-blog.netlify.com)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "quarto-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
